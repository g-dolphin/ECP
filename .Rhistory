## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
#
if(i>1 & inc$unq[i]=="no" & inc$unq[i-1]=="yes"){
inc$unq[i]<-"keep"
}
}
## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
#
if(i>1 & inc$unq[i]=="no" & inc$unq[i-1]=="yes"){
inc$unq[i]<-"keep"
} else{}
}
## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
View(inc)
inc['keeps']<-NA
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() > 1 & inc$unq[i-1]=="no"){
inc$keeps[i]<-"remove"
} else {
inc$unq[i]<-"keep"
}
}
inc['keeps']<-NA
for(i in 2:nrow(inc)){
inc$keeps[i]<-inc$unq[i-1]
}
View(inc)
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==5){
inc$keeps[i] <- "remove"
}
}
View(inc)
inc <- inc %>% filter(keeps != "remove")
inc<-read.delim(url("https://unstats.un.org/unsd/classifications/Econ/tables/ISIC/NACE2_ISIC4/NACE2_ISIC4.txt"),sep=',')
inc['NACE2code_n']<-as.numeric(inc$NACE2code)
# remove those with NA
inc <- inc %>% filter(!is.na(NACE2code_n))
## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==5){
inc$keeps[i] <- "remove"
}
}
inc <- inc %>% filter(!keeps == "remove")
inc<-read.delim(url("https://unstats.un.org/unsd/classifications/Econ/tables/ISIC/NACE2_ISIC4/NACE2_ISIC4.txt"),sep=',')
inc['NACE2code_n']<-as.numeric(inc$NACE2code)
# remove those with NA
inc <- inc %>% filter(!is.na(NACE2code_n))
## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==5){
inc$keeps[i] <- "remove"
}
}
View(inc)
inc <- inc %>% filter(is.na(keeps))
View(inc)
# then check the next
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
View(inc)
inc['keeps']<-NA
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==4){
inc$keeps[i] <- "remove"
}
}
inc <- inc %>% filter(is.na(keeps))
View(inc)
# very good, now there shouldn't be any duplicates anymore
inc <- inc %>% select(-c(unq,keeps))
View(inc)
length(unique(inc$NACE2code_n))
unique(adf$nace_id)
unique(inc$NACE2code_n)
## find ISIC code for each installation
adfa<-merge(adf,inc,by.x="nace_id_c",by.y="NACE2code",all.x=T)
View(adfa)
## find ISIC code for each installation
adfa<-merge(adf,inc,by.x="nace_id",by.y="NACE2code_n",all.x=T)
View(adfa)
unique(adfa$ISIC4code)
################################################################################
### file.path setup and packages ###############################################
wd<-file.path(here::here(),"_code","compilation","ecp","industry","4_euets")
setwd(wd)
library(here)
library(readxl)
library(dplyr)
################################################################################
### Import GLORIA index data
gversion<-"059"
fpe<-file.path("C:", "Users", "jomerkle",
"OneDrive - Norwegian University of Life Sciences",
"data",
"GLORIA",
gversion,
"Gloria_satellites_20240725")
# this just to create a vector of index numbers for those rows and columns we want to keep
# we want to keep only MRIO data, so remove the supply matrices within
39360/(2*120)
sec<-seq(1:39360) # sequence of numbers (for columns)
ser<-seq(1:39360) # sequence of numbers (for rows)
ones<-rep(1,times=120)
zeros<-rep(0,times=120)
oz<-c(ones,zeros)
full<-rep(oz,times=164)
sec[full==0]<-NA
ser[full==1]<-NA
cselector<-sec[!is.na(sec)] # removes NA values (from columns sequence)
rselector<-ser[!is.na(ser)] # removes NA values (from rows sequence)
rm(full,ones,oz,ser,sec,zeros) # remove objects no longer needed
# read data
sector_ind <- read_excel(file.path(fpe,"..",paste0("GLORIA_ReadMe_",gversion,".xlsx")),sheet = "Sectors")
region_ind <- read_excel(file.path(fpe,"..",paste0("GLORIA_ReadMe_",gversion,".xlsx")),sheet = "Regions")
sequential_ind <- read_excel(file.path(fpe,"..",paste0("GLORIA_ReadMe_",gversion,".xlsx")),sheet = "Sequential region-sector labels")
# shorten sequential_ind to reflect the non-product version
all_c_s<-sequential_ind$Sequential_regionSector_labels
short_c_s<-all_c_s[cselector]
sequential_ind$Sequential_regionSector_labels<-NA
sequential_ind<-sequential_ind[1:length(short_c_s),]
sequential_ind$Sequential_regionSector_labels<-short_c_s
# create full countrylabel and full sectorlabel vectors
cq<-region_ind$Region_names
fcql<-list()
for(i in 1:length(cq)){
fcql[[i]]<-rep(cq[i],times=nrow(sector_ind))
}
sequential_ind['fcq']<-do.call("c",fcql)
sequential_ind['fsq']<-rep(sector_ind$Sector_names,times=nrow(region_ind))
# store and tidy up
fcq<-sequential_ind$fcq
fsq<-sequential_ind$fsq
rm(fcql,region_ind,sector_ind,sequential_ind,all_c_s,cq,cselector,fpe,i,rselector,short_c_s)
################################################################################
### import eu ets permit data (downloaded from euets.info)
fpa<-file.path("C:", "Users", "jomerkle",
"OneDrive - Norwegian University of Life Sciences",
"data",
"Abrell",
"may_2024")
idf<-read.csv(file.path(fpa,"installation.csv"))
cdf<-read.csv(file.path(fpa,"compliance.csv"))
ndf<-read.csv(file.path(fpa,"nace_code.csv"))
# each allowance represents 1 t of ghg emissions
# surrendering an allowance means that you "use" the allowance.
# join together and keep only what we need
adf<-merge(cdf,idf,by.x="installation_id",by.y="id") %>%
select(installation_id,year,allocatedFree,allocatedTotal,allocated10c,
verified,verifiedCummulative,surrendered,surrenderedCummulative,
registry_id,nace15_id,nace20_id,nace_id)
# how many installations?
length(unique(adf$installation_id))
# how many verified emissions in 2019
sum(adf$verified[adf$year==2019],na.rm=T)
# how many allocated free permits in 2019
sum(adf$allocatedFree[adf$year==2019],na.rm=T)
# how many allocated total permits in 2019
sum(adf$allocatedTotal[adf$year==2019],na.rm=T)
# how many surrendered permits in 2019
sum(adf$surrendered[adf$year==2019],na.rm=T)
# how many surrenderedCummulative permits in 2019
sum(adf$surrenderedCummulative[adf$year==2019],na.rm=T)
# how many verifiedCummulative permits in 2019
sum(adf$verifiedCummulative[adf$year==2019],na.rm=T)
# check unique years and industries
unique(adf$year)
unique(adf$nace15_id)
unique(adf$nace20_id)
unique(adf$nace_id)
# take a look at which ones are NA.
dft<-adf %>% filter(is.na(nace_id))
unique(dft$installation_id)
# quite a few!
# how many?
n.instal.nid.nace<-length(unique(dft$installation_id))
rm(dft)
# we have got NA's here. Remove those cases. Undefined installations.
adf <- adf %>% filter(!is.na(nace_id))
unique(adf$nace15_id)
unique(adf$nace20_id)
unique(adf$nace_id)
# no NAs in nace_id, so use that one.
length(unique(adf$installation_id))
# any installations that are only part of years after 2023?
dft<-adf %>% filter(year>2023)
setdiff(dft$installation_id,adf$installation_id)
# no, they are all the same.
rm(dft)
# remove years after 2024
adf <- adf %>% filter(year %in% seq(2005,2024))
summary(adf$allocatedFree)
summary(adf$allocatedTotal)
summary(adf$allocated10c)
summary(adf$verified)
summary(adf$surrendered)
# we have quite a few NAs here. Let's test the cases
# allocatedTotal is never NA. So that's already good.
dft <- adf %>% filter(is.na(allocatedFree))
length(unique(dft$installation_id))
unique(dft$nace_id)
summary(dft$allocatedTotal)
# ok I see! All of these have zero allocated total
summary(dft$verified)
summary(dft$surrendered)
hist(dft$year)
rm(dft)
# ok so let's remove the rows with NA under allocatedFree
adf <- adf %>% filter(!is.na(allocatedFree))
length(unique(adf$installation_id))
# so now we have 15,548 installations in the dataset. This means that we have filtered out some years for some installations.
hist(adf$year)
# now let's check the allocated10c one
dft <- adf %>% filter(!is.na(allocated10c))
unique(dft$nace_id)
# mostly electricity and air transport, and then a few weird cases in Poland and Bulgaria.
# we add those to the free allocation
rm(dft)
# turn inapplicable cases to zero
adf$allocated10c[is.na(adf$allocated10c)]<-0
adf['allocatedFreeM']<-adf$allocatedFree+adf$allocated10c
# let's check the verified
dft <- adf %>% filter(is.na(verified))
hist(dft$year)
# ok so most of those cases are of course in 2024, but some are also earlier.
summary(dft$allocatedFree) # most (but not all) of these have zero allocated free
summary(dft$allocatedTotal) # most (but not all) have zero allocated total
unique(dft$nace_id) # all industries are represented
length(unique(dft$installation_id[dft$year==2024]))
rm(dft)
# remove cases with NA in verified
adf <- adf %>% filter(!is.na(verified))
length(unique(adf$installation_id))
# now let's check surrendered
summary(adf$surrendered)
dft <- adf %>% filter(is.na(surrendered))
hist(dft$year)
summary(dft$allocatedFree)
summary(dft$allocatedTotal)
summary(dft$verified)
summary(dft$allocatedTotal-dft$allocatedFree)
length(unique(dft$installation_id))
# remove cases with NA in surrendered
adf <- adf %>% filter(!is.na(surrendered))
length(unique(adf$installation_id))
unique(adf$nace_id)
# so now in this version we do not summarise.
unique(adf$nace_id) %>% sort()
rm(fpa,cdf,idf,ndf)
################################################################################
#### import concordance between nace and isic
inc<-read.delim(url("https://unstats.un.org/unsd/classifications/Econ/tables/ISIC/NACE2_ISIC4/NACE2_ISIC4.txt"),sep=',')
inc['NACE2code_n']<-as.numeric(inc$NACE2code)
# remove those with NA
inc <- inc %>% filter(!is.na(NACE2code_n))
## keep only the most general level (where we have duplicates like 7.1 and 7.10)
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
# first remove the duplicates at the highest level
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==5){
inc$keeps[i] <- "remove"
}
}
inc <- inc %>% filter(is.na(keeps))
# then check the next
inc['unq']<-NA
for(i in 1:nrow(inc)){
if(inc %>% filter(NACE2code_n==inc$NACE2code_n[i]) %>% nrow() == 1){
inc$unq[i]<-"yes"
} else {
inc$unq[i]<-"no"
}
}
inc['keeps']<-NA
for(i in 1:nrow(inc)){
if(inc$unq[i]=="no" & nchar(inc$NACE2code[i])==4){
inc$keeps[i] <- "remove"
}
}
inc <- inc %>% filter(is.na(keeps))
# very good, now there shouldn't be any duplicates anymore
inc <- inc %>% select(-c(unq,keeps))
length(unique(inc$NACE2code_n))
# confirmed
unique(adf$nace_id)
unique(inc$NACE2code_n)
## find ISIC code for each installation
adf<-merge(adf,inc,by.x="nace_id",by.y="NACE2code_n",all.x=T)
unique(adf$ISIC4code)
# tidy up
rm(inc)
################################################################################
#### read in GLORIA-ISIC concordance (this one was made by MM - a few hours of
# working through ISIC rev.4 classification
# using this resource: https://unstats.un.org/unsd/classifications/Econ/search)
gisic<-read_excel("GLORIA_ISICr4.xlsx",sheet = "Sectors")
# paste all classes, group and divisions in one column
gisic['all']<-NA
for(i in 1:nrow(gisic)){
gisic$all[i]<-paste(gisic$ISIC_classes[i],gisic$ISIC_group[i],gisic$ISIC_division[i],sep=";")
}
gisic$all<-gsub(" ","",gisic$all)
# put it into a list (for easier looping)
gl<-list()
for(i in 1:nrow(gisic)){
gl[[i]]<-strsplit(gisic$all[i],split=";")
gl[[i]]<-unlist(gl[[i]])
}
names(gl)<-gisic$Sector_names
# tidy up
rm(gisic,i)
# now loop across the permit dataframe and find gloria sector for each
# this is the main operation
adf['gloria_sector']<-NA
for(i in 1:nrow(adf)){
adf$gloria_sector[i]<-paste(which(sapply(gl, FUN=function(X) adf$ISIC4code[i] %in% X)),collapse="_")
}
View(adf)
unique(adf$gloria_sector)
# add the correct country names (corresponding to GLORIA)
countryconc<-data.frame(matrix(nrow=length(unique(adf$registry_id)),ncol=2))
colnames(countryconc)<-c("eu2dig","country")
countryconc$eu2dig<-unique(adf$registry_id)
countryconc$country[countryconc$eu2dig=="AT"]<-"Austria"
countryconc$country[countryconc$eu2dig=="BE"]<-"Belgium"
countryconc$country[countryconc$eu2dig=="BG"]<-"Bulgaria"
countryconc$country[countryconc$eu2dig=="CY"]<-"Cyprus"
countryconc$country[countryconc$eu2dig=="CZ"]<-"CSSR/Czech Republic (1990/1991)"
countryconc$country[countryconc$eu2dig=="DE"]<-"Germany"
countryconc$country[countryconc$eu2dig=="DK"]<-"Denmark"
countryconc$country[countryconc$eu2dig=="EE"]<-"Estonia"
countryconc$country[countryconc$eu2dig=="ES"]<-"Spain"
countryconc$country[countryconc$eu2dig=="FI"]<-"Finland"
countryconc$country[countryconc$eu2dig=="FR"]<-"France"
countryconc$country[countryconc$eu2dig=="GB"]<-"United Kingdom"
countryconc$country[countryconc$eu2dig=="GR"]<-"Greece"
countryconc$country[countryconc$eu2dig=="HR"]<-"Croatia"
countryconc$country[countryconc$eu2dig=="HU"]<-"Hungary"
countryconc$country[countryconc$eu2dig=="IE"]<-"Ireland"
countryconc$country[countryconc$eu2dig=="IS"]<-"Iceland"
countryconc$country[countryconc$eu2dig=="IT"]<-"Italy"
countryconc$country[countryconc$eu2dig=="LI"]<-"Liechtenstein"
countryconc$country[countryconc$eu2dig=="LT"]<-"Lithuania"
countryconc$country[countryconc$eu2dig=="LU"]<-"Luxembourg"
countryconc$country[countryconc$eu2dig=="LV"]<-"Latvia"
countryconc$country[countryconc$eu2dig=="MT"]<-"Malta"
countryconc$country[countryconc$eu2dig=="NL"]<-"Netherlands"
countryconc$country[countryconc$eu2dig=="NO"]<-"Norway"
countryconc$country[countryconc$eu2dig=="PL"]<-"Poland"
countryconc$country[countryconc$eu2dig=="PT"]<-"Portugal"
countryconc$country[countryconc$eu2dig=="RO"]<-"Romania"
countryconc$country[countryconc$eu2dig=="SE"]<-"Sweden"
countryconc$country[countryconc$eu2dig=="SI"]<-"Slovenia"
countryconc$country[countryconc$eu2dig=="SK"]<-"Slovakia"
countryconc$country[countryconc$eu2dig=="XI"]<-"United Kingdom"
# add to dataframe
adf<-merge(adf,countryconc,by.x="registry_id",by.y="eu2dig")
#tidy up
rm(countryconc,gl)
# add gloria names
sq<-unique(fsq)
adf['gloria_sector_name']<-NA
for(i in 1:nrow(adf)){
if(isTRUE(grepl("_",adf$gloria_sector[i]))){
adf$gloria_sector_name[i]<-"Aggregate (see variable gloria_sector)"
}else{
adf$gloria_sector_name[i]<-sq[as.numeric(adf$gloria_sector[i])]
}
}
### define a useful order of sectors and sector aggregates
sort(unique(adf$gloria_sector))
avlbls<-c("1_2_3_4",
"6_7",
"10","11","12",
"15",
"20",
"24","25","26","27","28","29",
"37","38","39","40",
"41_42_43_44_45",
"46","47",
"48_49",
"50",
"50_51",
"51",
"52_53",
"54","55","56","57","58","59","60","61","62","63","64",
"65_70",
"66",
"66_67_68_70",
"69","70","71","72","73",
"73_74_75_76",
"74",
"74_76",
"75","76","77",
"77_78_79_80_81_82_83_84",
"78_79_80_81_82_83_84",
"85","86","87","88","89","90","91","92","93",
"93_94",
"94","95","96","97","98","98_99","99",
"100",
"102","103","104","105","106","107","108","109","110","111","112","113","114","115","116","117","118"
)
# impose this order
adf<-adf %>% mutate(gloria_sector = factor(gloria_sector,levels=avlbls))
# now order the rows according to year, country, and gloria sector
adf<-adf %>% arrange(year,country,gloria_sector) %>% relocate(gloria_sector_name, .after=gloria_sector)
########### now the alternative summary, using weighted means and medians
# save old
adfo <- adf
# new variable paid share of permits
adf <- adf %>%
mutate(paidShare = (verified - allocatedFreeM)/ verified)
summary(adf$paidShare)
# coercing values below 0 to zero (only matters for mean, not median)
adf['paidShare_a']<-adf$paidShare
adf$paidShare_a[adf$paidShare_a<0]<-0
summary(adf$paidShare_a)
View(adf %>% filter(is.na(paidShare_a)))
# there are some NAs. These happen when there is zero verified emissions.
# let's remove those cases
adf <- adf %>% filter(verified>0)
summary(adf$paidShare_a)
# let's try an aggregation across countries
adfc <- adf %>% group_by(year,gloria_sector,gloria_sector_name) %>%
summarise(paidShare_a_md = median(paidShare_a),
paidShare_a_um = mean(paidShare_a),
paidShare_a_wm = weighted.mean(paidShare_a,verified),
n_installations = n())
# make a panel plot of the cross country aggregated data
adfc <- adfc %>% mutate(sector = paste(gloria_sector,gloria_sector_name))
library(ggplot2)
# first the median
ggplot(adfc,aes(x=year,y=paidShare_a_md)) + geom_line() + facet_wrap(vars(sector))
# then the unweighted mean
ggplot(adfc,aes(x=year,y=paidShare_a_um)) + geom_line() + facet_wrap(vars(sector))
# then the weighted mean
ggplot(adfc,aes(x=year,y=paidShare_a_wm)) + geom_line() + facet_wrap(vars(sector))
# think weighted mean makes most sense
gg<-ggplot(adfc,
aes(x=year,y=paidShare_a_wm)) +
geom_line() +
geom_text(aes(x=-Inf,y=Inf,label=gloria_sector_name),hjust=0,vjust=1,size=3)+
facet_wrap(vars(gloria_sector))
gg
View(adfc)
View(adf)
ggsave(gg,filename=paste0("euetsalloc",".svg"),
device="svg",
height=10,
width=20,
path=wd)
# then save
fpr<-file.path(here::here(),"_dataset","ecp","industry","ecp_gloria_sectors","euets_permits")
write.csv(adfc,file.path(fpr,"euetspermits_gloria.csv"),row.names=F)
