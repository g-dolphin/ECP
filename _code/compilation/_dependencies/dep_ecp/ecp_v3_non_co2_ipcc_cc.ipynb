{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159d28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate function from gen func file \n",
    "\n",
    "def concatenate(indir):\n",
    "    os.chdir(indir) #sets the current directory to 'indir'\n",
    "    fileList=glob.glob(\"*.csv\") # generates a list of csv files in the directory\n",
    "    dfList = []\n",
    "\n",
    "    for filename in fileList: #each iteration of the loop adding a dataframe to the list\n",
    "        df=pd.read_csv(filename, header=0)\n",
    "        dfList.append(df)\n",
    "\n",
    "    concatDf=pd.concat(dfList,axis=0) #'axis=0' ensures that we are concatenating vertically\n",
    "\n",
    "    return concatDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bd50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to create concordance between IPCC CODES in EDGAR data and IPCC CODES in WCPD \n",
    "\n",
    "# EDGAR N2O\n",
    "\n",
    "# confirmed IPCC_CODE_2006_FOR_STANDARD_REPORT\n",
    "\n",
    "N2O_confirmed = [\"1A1A\", \"1A1BC\", \"1A2\", \"1A3A\", \"1A3B\", \"1A3C\", \n",
    "                 \"1A3D\", \"1A3E\", \"1A4\", \"1A4\", \"1A5\", \"1B1\", \"1B2\",\n",
    "                 \"2B\", \"2G\", \"3A2\", \"3C1\", \"3C4\", \"3C5\", \"3C6\",\n",
    "                 \"4B\", \"4C\", \"4D\", \"5A\", \"5B\"]\n",
    "\n",
    "# EDGAR CH4 \n",
    "\n",
    "CH4_confirmed = [\"1A1A\", \"1A1BC\", \"1A2\", \"1A3A\", \"1A3B\", \"1A3C\", \n",
    "                 \"1A3D\", \"1A3E\", \"1A4\", \"1A5\", \"1B1\", \"1B2\",\n",
    "                 \"2B\", \"2C\", \"3A1\", \"3A2\", \"3C1\", \"3C7\",\n",
    "                 \"4A\", \"4B\", \"4C\", \"4D\", \"5B\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fddca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wcpd = Path('/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/WorldCarbonPricingDatabase/_dataset/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc14949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building policy features data frame for N2O\n"
     ]
    }
   ],
   "source": [
    "# Look at WCPD codes from WCPD concat file N2O\n",
    "\n",
    "    # Load WCPD data\n",
    "wcpd_n2o_ctry = concatenate(f\"{path_wcpd}/N2O/national\")\n",
    "wcpd_n2o_subnat = concatenate(f\"{path_wcpd}/N2O/subnational\")\n",
    "wcpd_n2o_all = pd.concat([wcpd_n2o_ctry, wcpd_n2o_subnat]).sort_values(by=[\"jurisdiction\", \"year\"])\n",
    "\n",
    "    # Clean and deduplicate\n",
    "wcpd_n2o_all[\"Product\"] = wcpd_n2o_all[\"Product\"].fillna('NA')\n",
    "wcpd_n2o_all = wcpd_n2o_all.drop_duplicates(subset=[\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"])\n",
    "\n",
    "    # If tax = 1 or ets = 1, summarize ipcc codes\n",
    "wcpd_n2o_all_policy = wcpd_n2o_all[(wcpd_n2o_all[\"tax\"] == 1) | (wcpd_n2o_all[\"ets\"] == 1)]\n",
    "wcpd_n2o_ipcc_codes = wcpd_n2o_all_policy[\"ipcc_code\"].unique().tolist()\n",
    "     \n",
    " # Load WCPD data\n",
    " \n",
    "wcpd_ch4_ctry = concatenate(f\"{path_wcpd}/CH4/national\")\n",
    "wcpd_ch4_subnat = concatenate(f\"{path_wcpd}/CH4/subnational\")\n",
    "wcpd_ch4_all = pd.concat([wcpd_ch4_ctry, wcpd_ch4_subnat]).sort_values(by=[\"jurisdiction\", \"year\"])\n",
    "\n",
    "    # Clean and deduplicate\n",
    "wcpd_ch4_all[\"Product\"] = wcpd_ch4_all[\"Product\"].fillna('NA')\n",
    "wcpd_ch4_all = wcpd_ch4_all.drop_duplicates(subset=[\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"])\n",
    "\n",
    "    # If tax = 1 or ets = 1, summarize ipcc codes to get lists of codes reported in coverage files \n",
    "wcpd_ch4_all_policy = wcpd_ch4_all[(wcpd_ch4_all[\"tax\"] == 1) | (wcpd_ch4_all[\"ets\"] == 1)]\n",
    "wcpd_ch4_ipcc_codes = wcpd_ch4_all_policy[\"ipcc_code\"].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e25e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_ipcc_substrings(wcpd_codes, confirmed_codes, max_len=None):\n",
    "    \"\"\"\n",
    "    Build successive-truncation columns for wcpd_codes and mark whether each truncation\n",
    "    matches any code in confirmed_codes.\n",
    "    Returns a DataFrame with:\n",
    "      - ipcc_code: original code\n",
    "      - code_len_{L}: substring of length L (for L = max_len .. 1)\n",
    "      - match_len_{L}: 1 if code_len_{L} in confirmed_codes else 0\n",
    "      - first_matched: the first (longest) substring found in confirmed_codes or None\n",
    "      - matched_len: length of the first matched substring or 0\n",
    "    wcpd_codes: iterable of strings (or a single-column DataFrame/Series)\n",
    "    confirmed_codes: iterable of strings\n",
    "    max_len: optional int to force maximum column length (defaults to longest wcpd code)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Normalize inputs\n",
    "    if isinstance(wcpd_codes, (pd.Series, pd.DataFrame)):\n",
    "        series = pd.Series(wcpd_codes.squeeze().astype(str).values)\n",
    "    else:\n",
    "        series = pd.Series([str(x) for x in list(wcpd_codes)])\n",
    "\n",
    "    confirmed_set = set([str(x) for x in confirmed_codes])\n",
    "\n",
    "    # determine maximum length to generate columns for\n",
    "    observed_max = series.str.len().max()\n",
    "    if max_len is None:\n",
    "        max_len = observed_max\n",
    "    max_len = int(max_len)\n",
    "\n",
    "    rows = []\n",
    "    for code in series:\n",
    "        L = len(code)\n",
    "        row = {\"ipcc_code\": code}\n",
    "        first_matched = None\n",
    "        matched_len = 0\n",
    "        # generate columns for lengths from max_len down to 1\n",
    "        for length in range(max_len, 0, -1):\n",
    "            if length <= L:\n",
    "                trunc = code[:length]\n",
    "            else:\n",
    "                trunc = \"\"  # shorter codes can't have a substring of this length\n",
    "            row[f\"code_len_{length}\"] = trunc if trunc != \"\" else None\n",
    "            is_match = 1 if (trunc in confirmed_set) else 0\n",
    "            row[f\"match_len_{length}\"] = is_match\n",
    "            if is_match and first_matched is None:\n",
    "                first_matched = trunc\n",
    "                matched_len = length\n",
    "        row[\"first_matched\"] = first_matched\n",
    "        row[\"matched_len\"] = matched_len\n",
    "        row[\"matched_confirmed_code\"] = first_matched\n",
    "        # matched_was_original: True if matched_len equals length of original code (i.e., untruncated matched)\n",
    "        row[\"matched_was_original\"] = (matched_len == L and matched_len > 0)\n",
    "        rows.append(row)\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    # keep columns in a sensible order: original, code_len.., match_len.., first_matched, matched_len\n",
    "    code_cols = [f\"code_len_{l}\" for l in range(max_len, 0, -1)]\n",
    "    match_cols = [f\"match_len_{l}\" for l in range(max_len, 0, -1)]\n",
    "    col_order = [\"ipcc_code\"] + code_cols + match_cols + [\"first_matched\", \"matched_len\", \"matched_confirmed_code\", \"matched_was_original\"]\n",
    "    # ensure all columns exist (in case some lengths > observed_max)\n",
    "    col_order = [c for c in col_order if c in df_out.columns]\n",
    "    return df_out[col_order]\n",
    "\n",
    "#Example usage with objects already in the notebook:\n",
    "    \n",
    "ch4_matches = match_ipcc_substrings(wcpd_ch4_ipcc_codes, CH4_confirmed)\n",
    "n2o_matches = match_ipcc_substrings(wcpd_ch4_ipcc_codes, N2O_confirmed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
