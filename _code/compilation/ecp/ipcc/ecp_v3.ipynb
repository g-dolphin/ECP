{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions-weighted carbon price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[\"ipcc_code\"].replace(to_replace=category_names_ipcc_can_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:176: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  usa[\"Gas\"].replace(to_replace={\"CO2 (combustion)\":\"CO2\", \"CO2 (non-combustion)\":\"CO2\"}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:198: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  usa[\"jurisdiction\"].replace(to_replace={\"Georgia\":\"Georgia_US\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%b-%d-%Y\")\n",
    "\n",
    "\n",
    "# changing file paths \n",
    "path_dependencies = '/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp'\n",
    "exec(open(path_dependencies+'/pkgs_and_directories.py').read())\n",
    "exec(open(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/WorldCarbonPricingDatabase/_code/_compilation/_dependencies/jurisdictions.py\").read())\n",
    "\n",
    "subnat_lists = {\"United States\":subnat_usa, \"Canada\":subnat_can, \"China\":subnat_chn}\n",
    "all_subnat_list = subnat_usa + subnat_can + subnat_chn\n",
    "\n",
    "gases = [\"CO2\"] # \"CH4\", \"N2O\", \"FGASES\" \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Institutional design (World Carbon Pricing Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "wcpd = {}\n",
    "\n",
    "for gas in gases: \n",
    "\n",
    "    # LOAD WCPD DATAFRAMES\n",
    "\n",
    "    wcpd_ctry = ecp_general.concatenate(path_wcpd+\"/\"+gas+\"/national\")\n",
    "    wcpd_subnat = ecp_general.concatenate(path_wcpd+\"/\"+gas+\"/subnational\")\n",
    "    wcpd_all = pd.concat([wcpd_ctry, wcpd_subnat]).sort_values(by=[\"jurisdiction\", \"year\"])\n",
    "\n",
    "    wcpd_all = wcpd_all.drop_duplicates(['jurisdiction', 'year', 'ipcc_code', 'Product']) # duplicates from WCPD need to be corrected\n",
    "\n",
    "    # ADD COLUMN WITH IEA SECTOR CODES\n",
    "    ipcc_iea_map = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_raw/_aux_files/ipcc2006_iea_category_codes.csv\", \n",
    "                    usecols=[\"ipcc_code\", \"FLOW\"])\n",
    "    \n",
    "    # goal should be to replace \"FLOW\" with IEA codes \n",
    "    \n",
    "    ipcc_iea_map.columns = [\"ipcc_code\", \"iea_code\"]\n",
    "\n",
    "\n",
    "    wcpd_all = wcpd_all.merge(ipcc_iea_map, on=[\"ipcc_code\"], how=\"left\")\n",
    "\n",
    "    # LISTS OF JURISDICTION NAMES\n",
    "\n",
    "    ctry_names = list(wcpd_ctry.jurisdiction.unique())\n",
    "    subnat_names = list(wcpd_subnat.jurisdiction.unique())\n",
    "\n",
    "    std_ctry_names = [x.replace(\".\", \"\").replace(\",\", \"\").replace(\" \", \"_\") for x in ctry_names]\n",
    "    countries_dic = dict(zip(ctry_names, std_ctry_names))\n",
    "\n",
    "    std_subnat_names = [x.replace(\".\", \"\").replace(\",\", \"\").replace(\" \", \"_\") for x in subnat_names]\n",
    "    subnat_dic = dict(zip(subnat_names, std_subnat_names))\n",
    "\n",
    "    if len(wcpd_all[wcpd_all.duplicated(['jurisdiction', 'year', 'ipcc_code', 'Product'], keep=False)] != 0):\n",
    "        print(\"The dataset contains duplicates!\")\n",
    "\n",
    "    # ADD COVERAGE FACTORS \n",
    "\n",
    "    wcpd_all = ecp_cov_fac.coverageFactors(wcpd_all, gas)\n",
    "\n",
    "    # MECHANISM OVERLAP \n",
    "    overlap = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/WorldCarbonPricingDatabase/_raw/overlap/overlap_mechanisms_\"+gas+\".csv\")\n",
    "\n",
    "    wcpd_all = ecp_overlap.overlap(wcpd_all, overlap)\n",
    "\n",
    "    wcpd[gas] = wcpd_all\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions\n",
    "## I. National jurisdictions \n",
    "### I.A Total GHG emissions (EDGAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Warming Potential values\n",
    "ipcc_gwp = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_raw/ghg_inventory/gwp_list.csv\")\n",
    "ipcc_gwp_list = dict(zip(ipcc_gwp.edgar_label, ipcc_gwp.ar5_gwp_100y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGASES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N2O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EDGAR_URL = \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/EDGAR/datasets/EDGAR_2024_GHG/\"\n",
    "\n",
    "dataURLs = {\"CH4\":EDGAR_URL+\"EDGAR_CH4_1970_2023.zip\",\n",
    "            \"CO2\":EDGAR_URL+\"IEA_EDGAR_CO2_1970_2023.zip\",\n",
    "            \"FGASES\":EDGAR_URL+\"EDGAR_F-gases_1990_2023.zip\",\n",
    "            \"N2O\":EDGAR_URL+\"EDGAR_N2O_1970_2023.zip\"}\n",
    "\n",
    "fileNames = {\"CH4\":'EDGAR_CH4_1970_2023.xlsx',\n",
    "            \"CO2\":\"IEA_EDGAR_CO2_1970_2023.xlsx\",\n",
    "            \"FGASES\":\"EDGAR_F-gases_1990_2023.xlsx\",\n",
    "            \"N2O\":\"EDGAR_N2O_1970_2023.xlsx\"}\n",
    "\n",
    "sheetNames = {\"CH4\":\"IPCC 2006\",\n",
    "              \"CO2\":\"IPCC 2006\",\n",
    "              \"FGASES\":\"IPCC 2006\",\n",
    "              \"N2O\":\"IPCC 2006\"}\n",
    "\n",
    "edgar_ghg = {}\n",
    "\n",
    "for gas in dataURLs.keys():\n",
    "    print(gas)\n",
    "    resp = requests.get(dataURLs[gas], verify=False).content\n",
    "\n",
    "    ## Open zip folder\n",
    "    myzip = ZipFile(BytesIO(resp))\n",
    "    #info = myzip.infolist()\n",
    "    #print(info)\n",
    "    \n",
    "    download = myzip.open(fileNames[gas])\n",
    "\n",
    "    df = pd.read_excel(download, header=0,\n",
    "                    sheet_name=sheetNames[gas], skiprows=[x for x in range(0,9)])\n",
    "    \n",
    "    edgar_ghg[gas] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concordance between EDGAR and World Bank country names\n",
    "edgar_wb_map = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/aux_files/edgar_wb_ctry_name_map.csv\")\n",
    "edgar_wb_map = edgar_wb_map.loc[~edgar_wb_map.ctry_name_wb.isnull()]\n",
    "\n",
    "edgar_wb_map = dict(zip(list(edgar_wb_map['ctry_name_edgar'].values), list(edgar_wb_map['ctry_name_wb'].values)))\n",
    "\n",
    "def process_gas_dataframe(gas, df, gwp_dict, edgar_wb_map):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter to fossil emissions\n",
    "    df = df[df[\"fossil_bio\"] == \"fossil\"]\n",
    "\n",
    "    # Drop and rename columns\n",
    "    df = df.drop(columns=[\"IPCC_annex\", \"C_group_IM24_sh\", \"Country_code_A3\", \"fossil_bio\", \"ipcc_code_2006_for_standard_report_name\"])\n",
    "    df.rename(columns={\"Name\": \"jurisdiction\"}, inplace=True)\n",
    "\n",
    "    # Aggregate and reshape\n",
    "    df = df.groupby([\"jurisdiction\", \"ipcc_code_2006_for_standard_report\", \"Substance\"]).sum().reset_index()\n",
    "    df = df.melt(\n",
    "        id_vars=[\"jurisdiction\", \"ipcc_code_2006_for_standard_report\", \"Substance\"],\n",
    "        var_name=\"year\",\n",
    "        value_name=gas\n",
    "    )\n",
    "\n",
    "    # Clean and map\n",
    "    df[\"year\"] = df[\"year\"].str[2:].astype(int)\n",
    "    df[\"jurisdiction\"] = df[\"jurisdiction\"].replace(edgar_wb_map)\n",
    "\n",
    "    # Apply GWP\n",
    "    if gas in [\"CO2\", \"CH4\", \"N2O\"]:\n",
    "        df[gas] = df[gas] * gwp_dict[gas]\n",
    "        df.drop(columns=[\"Substance\"], inplace=True)\n",
    "        \n",
    "    # for FGASES ? \n",
    "    else:\n",
    "        df_gwp = pd.DataFrame({\"Substance\": gwp_dict.keys(), \"gwp\": gwp_dict.values()})\n",
    "        df = df.merge(df_gwp, on=\"Substance\", how=\"left\")\n",
    "        df[gas] = df[gas] * df[\"gwp\"]\n",
    "        # drop for combined FGASES \n",
    "        df.drop(columns=[\"gwp\", \"Substance\"], inplace=True)\n",
    "        df = df.groupby([\"jurisdiction\", \"year\", \"ipcc_code_2006_for_standard_report\"]).sum().reset_index()\n",
    "\n",
    "    # Final cleanup\n",
    "    df.rename(columns={\"ipcc_code_2006_for_standard_report\": \"ipcc_code\"}, inplace=True)\n",
    "\n",
    "    df[\"ipcc_code\"] = df[\"ipcc_code\"].apply(lambda x: x.replace('.', '').upper())\n",
    "    df[\"ipcc_code\"] = df[\"ipcc_code\"].apply(lambda x: x.replace('_NORES', '').upper())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Main processing ---\n",
    "df_gases = pd.DataFrame()\n",
    "\n",
    "for gas, df in edgar_ghg.items():\n",
    "    df_gas = process_gas_dataframe(gas, df, ipcc_gwp_list, edgar_wb_map)\n",
    "\n",
    "    if df_gases.empty:\n",
    "        df_gases = df_gas\n",
    "    else:\n",
    "        df_gases = df_gases.merge(df_gas, on=[\"jurisdiction\", \"year\", \"ipcc_code\"], how=\"outer\")\n",
    "\n",
    "# Compute total GHGs\n",
    "df_gases[\"all_GHG\"] = df_gases[list(edgar_ghg.keys())].sum(axis=1)\n",
    "\n",
    "df_gases_jurAgg = df_gases.groupby([\"jurisdiction\", \"ipcc_code\", \"year\"]).sum().reset_index()\n",
    "\n",
    "# df_gases_jurAgg.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_national_total.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country names\n",
    "iea_wb_map = {'Australi':'Australia', \n",
    "            'Bosniaherz':'Bosnia and Herzegovina',\n",
    "            'Brunei':'Brunei Darussalam', \n",
    "            'Congo':'Congo, Rep.', \n",
    "            'Congorep':'Congo, Dem. Rep.',\n",
    "            'Costarica':'Costa Rica',\n",
    "            'Coteivoire':\"Cote d'Ivoire\", \n",
    "            'Czech':'Czech Republic',\n",
    "            'Dominicanr':'Dominican Republic',\n",
    "            'Egypt':'Egypt, Arab Rep.', \n",
    "            'Elsalvador':'El Salvador',\n",
    "            'Eqguinea':'Equatorial Guinea',\n",
    "            'Eswatini':'Lesotho', \n",
    "            'Hongkong':'Hong Kong, SAR', \n",
    "            'Iran':'Iran, Islamic, Rep.', \n",
    "            'Korea':'Korea, Rep.', \n",
    "            'Koreadpr':'Korea, Dem. Rep.', \n",
    "            'Kyrgyzstan':'Kyrgyz Republic', \n",
    "            'Lao':'Lao PDR', \n",
    "            'Luxembou':'Luxembourg',\n",
    "            'Nethland':'Netherlands',\n",
    "            'Northmaced':'North Macedonia',\n",
    "            'Nz':'New Zealand',\n",
    "            'Philippine':'Philippines',\n",
    "            'Russia':'Russian Federation',\n",
    "            'Saudiarabi':'Saudi Arabia', \n",
    "            'Slovakia':'Slovak Republic',\n",
    "            'Southafric':'South Africa',\n",
    "            'Srilanka':'Sri Lanka', \n",
    "            'Ssudan':'South Sudan', \n",
    "            'Switland':'Switzerland', \n",
    "            'Syria':'Syrian Arab Republic', \n",
    "            'Turkmenist':'Turkmenistan',\n",
    "            'Uae':'United Arab Emirates',\n",
    "            'Uk':'United Kingdom',\n",
    "            'Usa':'United States',\n",
    "            'Venezuela':'Venezuela, RB',\n",
    "            'Yemen':'Yemen, Rep.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME WITH TOTAL EMISSIONS WORLD\n",
    "\n",
    "df_gases_tot_world = df_gases_jurAgg.groupby(by=[\"year\"]).sum()\n",
    "df_gases_tot_world.reset_index(inplace=True)\n",
    "# df_gases_tot_world.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_world_total.csv',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.B National GHG Inventory (kt and % of totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:137: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(to_replace=iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  edgar_ghg[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:137: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(to_replace=iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  edgar_ghg[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "inventory_nat_ch4 = ecp_inv_nat.inventory_non_co2(wcpd_all, \"CH4\", ctry_names, iea_wb_map, edgar_wb_map)\n",
    "inventory_nat_n2o = ecp_inv_nat.inventory_non_co2(wcpd_all, \"N2O\", ctry_names, iea_wb_map, edgar_wb_map)\n",
    "\n",
    "inventory_nat_ch4.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_ch4_ipcc.csv',index=None)\n",
    "inventory_nat_n2o.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_n2o_ipcc.csv',index=None)\n",
    "\n",
    "\n",
    "# test for the new IEA concordance \n",
    "#inventory_nonco2_iea = ecp_inv_nat.inventory_non_co2_iea(iea_wb_map)\n",
    "# output for comparison with EDGAR \n",
    "#inventory_nonco2_iea.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_non_co2_ipcc.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"CO2\"].replace(to_replace={\"..\":np.nan, \"x\":np.nan, \"c\":np.nan},\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"ProductCat\"].replace(to_replace={product:key}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(to_replace=iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:82: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ippu_fug_nat[\"jurisdiction\"].replace(to_replace=edgar_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ippu_fug_nat[\"jurisdiction\"].replace(to_replace=edgar_wb_map, inplace=True)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidIndexError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m inventory_nat_co2 = \u001b[43mecp_inv_nat\u001b[49m\u001b[43m.\u001b[49m\u001b[43minventory_co2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwcpd_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctry_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miea_wb_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_gases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgar_wb_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m inventories = {\u001b[33m\"\u001b[39m\u001b[33mCO2\u001b[39m\u001b[33m\"\u001b[39m:inventory_nat_co2, \u001b[33m\"\u001b[39m\u001b[33mCH4\u001b[39m\u001b[33m\"\u001b[39m:inventory_nat_ch4, \u001b[33m\"\u001b[39m\u001b[33mN2O\u001b[39m\u001b[33m\"\u001b[39m:inventory_nat_n2o, \u001b[33m\"\u001b[39m\u001b[33mFGASES\u001b[39m\u001b[33m\"\u001b[39m:inventory_nat_fgases}\n\u001b[32m      4\u001b[39m inventories_wldSect = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\OneDrive - rff\\Documents\\RFF Organization\\Research Documents\\WCPD\\ECP\\_code\\compilation\\_dependencies\\dep_ecp\\inventory_preproc_nat.py:96\u001b[39m, in \u001b[36minventory_co2\u001b[39m\u001b[34m(wcpd_df, jur_names, iea_wb_map, edgar_ghg_df, edgar_wb_map)\u001b[39m\n\u001b[32m     93\u001b[39m inventory_nat = wcpd_df.loc[wcpd_df.jurisdiction.isin(jur_names), [\u001b[33m\"\u001b[39m\u001b[33mjurisdiction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mipcc_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33miea_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProduct\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     94\u001b[39m inventory_nat[[\u001b[33m\"\u001b[39m\u001b[33miea_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProduct\u001b[39m\u001b[33m\"\u001b[39m]] = inventory_nat[[\u001b[33m\"\u001b[39m\u001b[33miea_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProduct\u001b[39m\u001b[33m\"\u001b[39m]].fillna(\u001b[33m\"\u001b[39m\u001b[33mNA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m combined_nat = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcombustion_nat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mippu_fug_nat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m inventory_nat = inventory_nat.merge(combined_nat, on=[\u001b[33m\"\u001b[39m\u001b[33mjurisdiction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mipcc_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33miea_code\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mProduct\u001b[39m\u001b[33m\"\u001b[39m], how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inventory_nat\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    678\u001b[39m         obj_labels = obj.axes[\u001b[32m1\u001b[39m - ax]\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels.equals(obj_labels):\n\u001b[32m--> \u001b[39m\u001b[32m680\u001b[39m             indexers[ax] = \u001b[43mobj_labels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m    684\u001b[39m new_data = concatenate_managers(\n\u001b[32m    685\u001b[39m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m.new_axes, concat_axis=\u001b[38;5;28mself\u001b[39m.bm_axis, copy=\u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m    686\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[39m, in \u001b[36mIndex.get_indexer\u001b[39m\u001b[34m(self, target, method, limit, tolerance)\u001b[39m\n\u001b[32m   3882\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_method(method, limit, tolerance)\n\u001b[32m   3884\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_as_unique:\n\u001b[32m-> \u001b[39m\u001b[32m3885\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m._requires_unique_msg)\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) == \u001b[32m0\u001b[39m:\n\u001b[32m   3888\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array([], dtype=np.intp)\n",
      "\u001b[31mInvalidIndexError\u001b[39m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "inventory_nat_co2 = ecp_inv_nat.inventory_co2(wcpd_all, ctry_names, iea_wb_map, df_gases, edgar_wb_map)\n",
    "\n",
    "inventories = {\"CO2\":inventory_nat_co2, \"CH4\":inventory_nat_ch4, \"N2O\":inventory_nat_n2o, \"FGASES\":inventory_nat_fgases}\n",
    "inventories_wldSect = {}\n",
    "\n",
    "for gas in gases:\n",
    "    inventory_share = ecp_inv_share.emissions_share(inventories[gas], df_gases_jurAgg, df_gases_tot_world, gas)\n",
    "\n",
    "    if gas == \"CO2\":\n",
    "        merge_keys = [\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]\n",
    "        columns = [\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\", gas]\n",
    "    else:\n",
    "        merge_keys = [\"jurisdiction\", \"year\", \"ipcc_code\"]\n",
    "        columns = [\"jurisdiction\", \"year\", \"ipcc_code\", gas]\n",
    "\n",
    "    inventories[gas] = pd.merge(inventories[gas], inventory_share, on=merge_keys, how=\"left\")\n",
    "\n",
    "    inventories[gas].to_csv(\"/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    # Shares of total world sector emissions\n",
    "    sectors_wld_total = inventories[gas][columns].groupby([\"ipcc_code\", \"year\"]).sum()\n",
    "    sectors_wld_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_wldSect[gas] = ecp_inv_share.emissions_share_wld_sectors(inventories[gas], sectors_wld_total, gas, \"national\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    for ctry in countries_dic.keys():\n",
    "        inventories[gas].loc[inventories[gas].jurisdiction==ctry, :].to_csv(\"/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/national/\"+gas+\"/inventory_\"+gas+\"_\"+countries_dic[ctry]+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Subnational jurisdictions\n",
    "### II.A Total GHG emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gases_tot_subnat = ecp_inv_subnat.subnat_total()\n",
    "df_gases_tot_subnat.to_csv('/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_subnat_total.csv',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.B Subnational inventory (kt and % totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventories_subnat = {}\n",
    "inventories_subnat_wldSect = {}\n",
    "inventories_subnat_ctrySect = {}\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "    inventory_subnat = ecp_inv_subnat.inventory_subnat(wcpd[gas], subnat_names, ipcc_iea_map, gas)\n",
    "\n",
    "    inventory_subnat_share = ecp_inv_share.emissions_share(inventory_subnat, \n",
    "                                                           df_gases_tot_subnat, df_gases_tot_world, gas, df_gases_jurAgg, \"subnational\")\n",
    "\n",
    "    merge_keys = [\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\"]\n",
    "    columns = [\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", gas]\n",
    "\n",
    "    inventories_subnat[gas] = pd.merge(inventory_subnat, inventory_subnat_share, on=merge_keys, how=\"left\")\n",
    "    inventories_subnat[gas].to_csv(\"/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_subnat_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    # Shares of total world sector emissions\n",
    "    sectors_wld_total = inventories[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", gas]].groupby([\"ipcc_code\", \"year\"]).sum()\n",
    "    sectors_wld_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_subnat_wldSect[gas] = ecp_inv_share.emissions_share_wld_sectors(inventories_subnat[gas], sectors_wld_total, gas, \"subnational\")\n",
    "\n",
    "    # Shares of total country-sector emissions\n",
    "    sectors_ctry_total = inventories[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", gas]].groupby([\"jurisdiction\", \"year\", \"ipcc_code\"]).sum()\n",
    "    sectors_ctry_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_subnat_ctrySect[gas] = ecp_inv_share.emissions_share_ctry_sectors(inventories_subnat[gas], sectors_ctry_total, gas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    inventories_subnat_ctrySect[gas].to_csv(\"/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/subnational/\"+gas+\"/sector_level/inventory_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    for jur in subnat_dic.keys():\n",
    "        inventories_subnat[gas].loc[inventories_subnat[gas].jurisdiction==jur, :].to_csv(\"/Users/gd/OneDrive - rff/Documents/Research/projects/ecp/ecp_dataset/source_data/ghg_inventory/processed/subnational/\"+gas+\"/inventory_\"+gas+\"_\"+subnat_dic[jur]+\".csv\", index=None)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage \n",
    "## I. Disaggregated coverage dataframes\n",
    "\n",
    "** Note: National and subnational inventories do not have the same level of disaggregation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_nat = {}\n",
    "coverage_subnat = {}\n",
    "coverage = {}\n",
    "coverage_sect = {}\n",
    "coverage_nat_sect = {}\n",
    "coverage_subnat_sect = {}\n",
    "\n",
    "lastInvYear = {\"national\":2022, \"subnat\":2018}\n",
    "lastDbYear = 2024\n",
    "\n",
    "# SHARE OF JURISDICTIONS TOTAL EMISSIONS\n",
    "for gas in gases:\n",
    "\n",
    "    coverage_nat[gas] = ecp_coverage.coverage(inventories[gas], lastInvYear[\"national\"], lastDbYear, wcpd[gas], gas,\n",
    "                                              False, \"national\")\n",
    "    coverage_subnat[gas] = ecp_coverage.coverage(inventories_subnat[gas], lastInvYear[\"subnat\"], lastDbYear, wcpd[gas], gas,\n",
    "                                                 False, \"subnational\")\n",
    "\n",
    "    coverage_all = pd.concat([coverage_nat[gas], coverage_subnat[gas]])\n",
    "    coverage_all = coverage_all.loc[coverage_all[\"jurisdiction\"]!=\"World\", :]\n",
    "\n",
    "    # Coverage figures should be calculated only based on aggregation of the most disaggregated flows, not their higher-level aggregation. \n",
    "    # Otherwise this might result in double counting. Hence aggregate sectors should be dropped from coverage dataframe.\n",
    "    # It also currently excludes coverage of international aviation ('ABFLOW039') and marine ('ABFLOW040') bunkers \n",
    "    # as they are currently excluded from national total emissions.\n",
    "    # Drop combustion sectors that are aggregation of lower level sectors and concatenate all coverage dataframes into a single one*\n",
    "\n",
    "    flow_excl = ['1A', '1A1A', '1A1C', '1A2', '1A3'] #'1A1C' is exluded here as ABFLOW011 emissions are attributed twice (to both 1A1B and 1A1C)\n",
    "    coverage_all = coverage_all.loc[~coverage_all.ipcc_code.isin(flow_excl), :]\n",
    "\n",
    "    coverage[gas] = coverage_all\n",
    "\n",
    "\n",
    "    # SHARE OF SECTORS' GLOBAL TOTAL EMISSIONS\n",
    "\n",
    "    coverage_nat_sect[gas] = ecp_coverage.coverage(inventories_wldSect[gas], lastInvYear[\"national\"], lastDbYear, wcpd[gas], gas,\n",
    "                                True, \"national\")\n",
    "    coverage_subnat_sect[gas] = ecp_coverage.coverage(inventories_subnat_wldSect[gas], lastInvYear[\"subnat\"], lastDbYear, wcpd[gas], gas,\n",
    "                                    True, \"subnational\")\n",
    "\n",
    "    coverage_sect_all = pd.concat([coverage_nat_sect[gas], coverage_subnat_sect[gas]])\n",
    "    coverage_sect_all = coverage_sect_all.loc[coverage_sect_all[\"jurisdiction\"]!=\"World\", :]\n",
    "\n",
    "    coverage_sect[gas] = coverage_sect_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Aggregate coverage\n",
    "\n",
    "- \"The sum over all pricing mechanisms\" of [emissions_share x coverage_factor] minus the overlapping coverage\n",
    "\n",
    "We account for the fact that more than one tax scheme or ets scheme can apply to the same emissions. However, covered emissions should be counted only once when covered by one or more scheme. To calculate overlapping coverage at the sector-fuel level, we use the `overlap_` variable in `wcpd_all` dataframe created above.\n",
    "\n",
    "### II.1 jurisdictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cov = {}\n",
    "\n",
    "for gas in gases:\n",
    "    # Create dataframe to contain aggregate coverage\n",
    "    coverage_agg = coverage_all[[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]]\n",
    "\n",
    "    # TAXES\n",
    "\n",
    "    cov_tax_columns_jurGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"jurGHG\" in x]\n",
    "    cov_tax_columns_jurGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"jur\"+gas in x]\n",
    "    cov_tax_columns_wldGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"wldGHG\" in x]\n",
    "    cov_tax_columns_wldGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"wld\"+gas in x]\n",
    "    cov_tax_columns_supraGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"supraGHG\" in x]\n",
    "    cov_tax_columns_supraGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"supra\"+gas in x]\n",
    "\n",
    "    tax_columns = {\"cov_tax_\"+gas+\"_jurGHG\":cov_tax_columns_jurGHG, \"cov_tax_\"+gas+\"_jur\"+gas:cov_tax_columns_jurGas, \n",
    "                \"cov_tax_\"+gas+\"_wldGHG\":cov_tax_columns_wldGHG, \"cov_tax_\"+gas+\"_wld\"+gas:cov_tax_columns_wldGas, \n",
    "                \"cov_tax_\"+gas+\"_supraGHG\":cov_tax_columns_supraGHG, \"cov_tax_\"+gas+\"_supra\"+gas:cov_tax_columns_supraGas}\n",
    "\n",
    "    # ETS\n",
    "\n",
    "    cov_ets_columns_jurGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"jurGHG\" in x]\n",
    "    cov_ets_columns_jurGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"jur\"+gas in x]\n",
    "    cov_ets_columns_wldGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"wldGHG\" in x]\n",
    "    cov_ets_columns_wldGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"wld\"+gas in x]\n",
    "    cov_ets_columns_supraGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"supraGHG\" in x]\n",
    "    cov_ets_columns_supraGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"supra\"+gas in x]\n",
    "\n",
    "    ets_columns = {\"cov_ets_\"+gas+\"_jurGHG\":cov_ets_columns_jurGHG, \"cov_ets_\"+gas+\"_jur\"+gas:cov_ets_columns_jurGas, \n",
    "                \"cov_ets_\"+gas+\"_wldGHG\": cov_ets_columns_wldGHG, \"cov_ets_\"+gas+\"_wld\"+gas:cov_ets_columns_wldGas, \n",
    "                \"cov_ets_\"+gas+\"_supraGHG\":cov_ets_columns_supraGHG, \"cov_ets_\"+gas+\"_supra\"+gas:cov_ets_columns_supraGas}\n",
    "\n",
    "    # ALL INSTRUMENTS\n",
    "\n",
    "    cov_all_columns_jurGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"jurGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_jurGas = [x for x in coverage_all.columns if \"cov_\" in x and \"jur\"+gas in x and \"overlap\" not in x]\n",
    "    cov_all_columns_wldGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"wldGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_wldGas = [x for x in coverage_all.columns if \"cov_\" in x and \"wld\"+gas in x and \"overlap\" not in x]\n",
    "    cov_all_columns_supraGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"supraGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_supraGas = [x for x in coverage_all.columns if \"cov_\" in x and \"supra\"+gas in x and \"overlap\" not in x]\n",
    "\n",
    "    all_columns = {\"cov_all_\"+gas+\"_jurGHG\":cov_all_columns_jurGHG, \"cov_all_\"+gas+\"_jur\"+gas:cov_all_columns_jurGas, \n",
    "                \"cov_all_\"+gas+\"_wldGHG\":cov_all_columns_wldGHG, \"cov_all_\"+gas+\"_wld\"+gas:cov_all_columns_wldGas, \n",
    "                \"cov_all_\"+gas+\"_supraGHG\":cov_all_columns_supraGHG, \"cov_all_\"+gas+\"_supra\"+gas:cov_all_columns_supraGas}\n",
    "\n",
    "\n",
    "    all_overlap_dic = {\"cov_all_\"+gas+\"_jurGHG\":\"cov_overlap_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_jur\"+gas:\"cov_overlap_\"+gas+\"_jur\"+gas, \n",
    "                    \"cov_all_\"+gas+\"_wldGHG\":\"cov_overlap_\"+gas+\"_wldGHG\", \"cov_all_\"+gas+\"_wld\"+gas:\"cov_overlap_\"+gas+\"_wld\"+gas, \n",
    "                    \"cov_all_\"+gas+\"_supraGHG\":\"cov_overlap_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_supra\"+gas:\"cov_overlap_\"+gas+\"_supra\"+gas}\n",
    "\n",
    "    # Calculation of coverage\n",
    "\n",
    "    # An adjustment to the coverage function needs to be made. The function's output needs to include i) overlap across taxes, ii) overlap across ets, \n",
    "    # iii) overlap across all instruments\n",
    "\n",
    "    # A. Sum across all instruments (columns)\n",
    "\n",
    "    for dic in [tax_columns, ets_columns]: # [all_columns]\n",
    "        for key in dic.keys():\n",
    "            # sum across all instrument columns and substract overlaping coverage\n",
    "            coverage_agg[key] = coverage_all[dic[key]].sum(axis=1) # - coverage_all[all_overlap_dic[key]]\n",
    "\n",
    "    for dic in [all_columns]:\n",
    "        for key in dic.keys():\n",
    "            coverage_agg[key] = coverage_all[dic[key]].sum(axis=1) - coverage_all[all_overlap_dic[key]]\n",
    "\n",
    "    # B. Sum across all emission categories (rows)\n",
    "    coverage_agg = coverage_agg.groupby(['jurisdiction','year']).sum()\n",
    "    coverage_agg.reset_index(inplace=True)\n",
    "\n",
    "    agg_cov[gas] = coverage_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORLD TOTAL COVERAGE \n",
    "\n",
    "for gas in gases:\n",
    "    cov_world_agg = agg_cov[gas][[\"jurisdiction\",\"year\", \"cov_tax_\"+gas+\"_wld\"+gas, \"cov_ets_\"+gas+\"_wld\"+gas, \n",
    "                                        \"cov_tax_\"+gas+\"_wldGHG\", \"cov_ets_\"+gas+\"_wldGHG\"]]\n",
    "\n",
    "    cov_world_agg.reset_index(inplace=True)\n",
    "    cov_world_agg = cov_world_agg.groupby(['year']).sum()\n",
    "\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"] + cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas] + cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas]\n",
    "    \n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_wldGHG\"] = cov_world_agg[\"cov_all_\"+gas+\"_jurGHG\"]\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_wld\"+gas] = cov_world_agg[\"cov_all_\"+gas+\"_jur\"+gas]\n",
    "\n",
    "    # addind values in 'jur' columns for the \"World\" jurisdiction\n",
    "    cov_world_agg[\"cov_tax_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_ets_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_tax_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas]\n",
    "    cov_world_agg[\"cov_ets_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas]\n",
    "\n",
    "#    cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"] = \"NA\"\n",
    "#    cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"] = \"NA\"\n",
    "#    cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas] = \"NA\"\n",
    "#    cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas] = \"NA\"\n",
    "\n",
    "    cov_world_agg[\"jurisdiction\"] = \"World\"\n",
    "\n",
    "    cov_world_agg.drop(\"index\", axis=1, inplace=True)\n",
    "    cov_world_agg.reset_index(inplace=True)\n",
    "\n",
    "    agg_cov[gas] = pd.concat([agg_cov[gas], cov_world_agg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# National-level coverage from subnational schemes\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "      for subnat_list in subnat_lists.keys():\n",
    "            temp = agg_cov[gas].loc[agg_cov[gas].jurisdiction.isin(subnat_lists[subnat_list]), :]\n",
    "            temp = temp.groupby([\"year\"]).sum()\n",
    "            temp.reset_index(inplace=True)\n",
    "            temp[\"jurisdiction\"] = subnat_list+\"_sub\" # indicating it is the country-level coverage from subnational mechanisms\n",
    "\n",
    "            temp[[\"cov_tax_\"+gas+\"_jurGHG\", \"cov_tax_\"+gas+\"_jur\"+gas, \"cov_ets_\"+gas+\"_jurGHG\", \"cov_ets_\"+gas+\"_jur\"+gas,\n",
    "                  \"cov_all_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_jur\"+gas]] = np.nan\n",
    "            \n",
    "            swap_list = {\"cov_tax_\"+gas+\"_jurGHG\":\"cov_tax_\"+gas+\"_supraGHG\", \"cov_tax_\"+gas+\"_jur\"+gas:\"cov_tax_\"+gas+\"_supra\"+gas, \"cov_ets_\"+gas+\"_jurGHG\":\"cov_ets_\"+gas+\"_supraGHG\", \n",
    "                        \"cov_ets_\"+gas+\"_jur\"+gas:\"cov_ets_\"+gas+\"_supra\"+gas, \"cov_all_\"+gas+\"_jurGHG\":\"cov_all_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_jur\"+gas:\"cov_all_\"+gas+\"_supra\"+gas,\n",
    "                        \"cov_tax_\"+gas+\"_supraGHG\":\"cov_tax_\"+gas+\"_jurGHG\", \"cov_tax_\"+gas+\"_supra\"+gas:\"cov_tax_\"+gas+\"_jur\"+gas, \"cov_ets_\"+gas+\"_supraGHG\":\"cov_ets_\"+gas+\"_jurGHG\", \n",
    "                        \"cov_ets_\"+gas+\"_supra\"+gas:\"cov_ets_\"+gas+\"_jur\"+gas, \"cov_all_\"+gas+\"_supraGHG\":\"cov_all_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_supra\"+gas:\"cov_all_\"+gas+\"_jur\"+gas}\n",
    "            \n",
    "            temp.rename(columns=swap_list, inplace=True)\n",
    "            \n",
    "            temp_nat = agg_cov[gas].loc[agg_cov[gas].jurisdiction == subnat_list, :]\n",
    "\n",
    "            temp_nat_subnat = pd.concat([temp_nat, temp])\n",
    "            temp_nat_subnat = temp_nat_subnat.groupby([\"year\"]).sum() # summing country-level coverage from country-level and subnational mechanisms\n",
    "            temp_nat_subnat.reset_index(inplace=True)\n",
    "\n",
    "            temp_nat_subnat[\"jurisdiction\"] = subnat_list\n",
    "\n",
    "            agg_cov[gas] = agg_cov[gas].loc[agg_cov[gas].jurisdiction != subnat_list, :]\n",
    "            \n",
    "            agg_cov[gas] = pd.concat([agg_cov[gas], temp_nat_subnat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values for all entries of 'supra' columns of national jurisdictions\n",
    "\n",
    "all_subnat_list = subnat_usa + subnat_can + subnat_chn\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "    supra_cols = [\"cov_tax_\"+gas+\"_supraGHG\", \"cov_tax_\"+gas+\"_supra\"+gas, \"cov_ets_\"+gas+\"_supraGHG\", \n",
    "                \"cov_ets_\"+gas+\"_supra\"+gas, \"cov_all_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_supra\"+gas]\n",
    "\n",
    "    agg_cov[gas].loc[~agg_cov[gas].jurisdiction.isin(all_subnat_list), supra_cols] = np.nan\n",
    "\n",
    "    coverage_agg_OUT = agg_cov[gas].fillna(\"NA\")\n",
    "    coverage_agg_OUT.sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/coverage/tot_coverage_jurisdiction_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 World sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_WldSect = {}\n",
    "\n",
    "for gas in gases:\n",
    "    \n",
    "    coverage_sect[gas]\n",
    "\n",
    "    cov_tax_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_tax\" in x and \"wld_sect\" in x]\n",
    "    cov_ets_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_ets\" in x and \"wld_sect\" in x]\n",
    "    cov_all_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_\" in x and \"wld_sect\" in x]\n",
    "\n",
    "    tax_columns = {\"cov_tax_\"+gas+\"_WldSect\"+gas:cov_tax_columns_WldSectGas}\n",
    "    ets_columns = {\"cov_ets_\"+gas+\"_WldSect\"+gas:cov_ets_columns_WldSectGas}\n",
    "    all_columns = {\"cov_all_\"+gas+\"_WldSect\"+gas:cov_all_columns_WldSectGas}\n",
    "\n",
    "    coverage_sect_agg_schemes = coverage_sect[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]]\n",
    "\n",
    "    for dic in [tax_columns, ets_columns, all_columns]:\n",
    "        for key in dic.keys():\n",
    "            coverage_sect_agg_schemes[key] = coverage_sect[gas][dic[key]].sum(axis=1)\n",
    "\n",
    "    coverage_WldSect[gas] = coverage_sect_agg_schemes.groupby(['ipcc_code','year']).sum()\n",
    "    coverage_WldSect[gas].reset_index(inplace=True)\n",
    "\n",
    "    coverage_WldSect[gas].to_csv(path_aux_data+\"/data/coverage/tot_coverage_world_sectors_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions-weighted Carbon Price (ECP)\n",
    "Combines: (i) (total) coverage of ETS and associated price, (ii) user-fuel coverage of taxes and associated tax rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_usd = {}\n",
    "\n",
    "for gas in gases:\n",
    "    # simply execute function to create cFlxRate series\n",
    "    ecp_cur_conv.cur_conv(wcpd[gas], gas, subnat_can, subnat_usa, subnat_chn, False, None)\n",
    "\n",
    "    wcpd_usd = ecp_cur_conv.cur_conv(wcpd[gas], gas, subnat_can, subnat_usa, subnat_chn, True, 2021)\n",
    "\n",
    "    #Bring together calculated emissions share at sector and sector-fuel level and carbon prices in constant USD\n",
    "\n",
    "    id_columns = [x for x in wcpd_usd.columns if bool(re.match(re.compile(\"ets.+id\"), x))==True or bool(re.match(re.compile(\"tax.+id\"), x))==True]\n",
    "    price_columns = [x for x in wcpd_usd.columns if bool(re.match(re.compile(\"ets.+price_usd_k\"), x))==True or bool(re.match(re.compile(\"tax.+rate.+usd_k\"), x))==True]\n",
    "\n",
    "    prices_usd[gas] = wcpd_usd[['jurisdiction', 'year', 'ipcc_code', 'iea_code', 'Product']+price_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. ECP from ETS and taxes (time-varying and fixed weights, jurisdiction level)\n",
    "\n",
    "National and subnational jurisdictions, sectoral level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_variables_map = {}\n",
    "\n",
    "ecp_tv = {}\n",
    "ecp_fixed = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_tv_nat = ecp_wav.ecp(coverage_nat[gas], prices_usd[gas], \"national\", gas, flow_excl, \"time_varying\", sectors=False)\n",
    "    ecp_tv_subnat = ecp_wav.ecp(coverage_subnat[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"time_varying\", sectors=False)\n",
    "    \n",
    "    ecp_tv[gas] = pd.concat([ecp_tv_nat, ecp_tv_subnat])\n",
    "\n",
    "    ecp_fixed_nat = ecp_wav.ecp(coverage_nat[gas], prices_usd[gas], \"national\", gas, flow_excl, \"fixed\", 2015, sectors=False)\n",
    "    ecp_fixed_subnat = ecp_wav.ecp(coverage_subnat[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"fixed\", 2015, sectors=False)\n",
    "    \n",
    "    ecp_fixed[gas] = pd.concat([ecp_fixed_nat, ecp_fixed_subnat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_tv_sect = {}\n",
    "ecp_fixed_sect = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_tv_nat_sect = ecp_wav.ecp(coverage_nat_sect[gas], prices_usd[gas], \"national\", gas, flow_excl, \"time_varying\", sectors=True)\n",
    "    ecp_tv_subnat_sect = ecp_wav.ecp(coverage_subnat_sect[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"time_varying\", sectors=True)\n",
    "    \n",
    "    ecp_tv_sect[gas] = pd.concat([ecp_tv_nat_sect, ecp_tv_subnat_sect])\n",
    "    ecp_tv_nat_sect.groupby([\"ipcc_code\", \"year\"]).sum().to_csv(path_aux_data+\"/data/ecp/ecp_sectors_wld/world_sectoral_ecp_\"+gas+\".csv\")\n",
    "\n",
    "    ecp_fixed_nat_sect = ecp_wav.ecp(coverage_nat_sect[gas], prices_usd[gas], \"national\", gas, flow_excl, \"fixed\", 2015, sectors=True)\n",
    "    ecp_fixed_subnat_sect = ecp_wav.ecp(coverage_subnat_sect[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"fixed\", 2015, sectors=True)\n",
    "    \n",
    "    ecp_fixed_sect[gas] = pd.concat([ecp_fixed_nat, ecp_fixed_subnat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_tv_agg = {}\n",
    "ecp_fixed_agg = {}\n",
    "\n",
    "for gas in gases: \n",
    "    ecp_tv_agg[gas] = ecp_wav.ecp_aggregation(ecp_tv[gas], gas)\n",
    "    ecp_fixed_agg[gas] = ecp_wav.ecp_aggregation(ecp_fixed[gas], gas)\n",
    "\n",
    "    # National-level ecp from subnational schemes        \n",
    "\n",
    "    for key in subnat_lists.keys():\n",
    "        ecp_tv_agg[gas] = ecp_wav.national_from_subnat(ecp_tv_agg[gas], subnat_lists[key], key, gas)\n",
    "        ecp_fixed_agg[gas] = ecp_wav.national_from_subnat(ecp_fixed_agg[gas], subnat_lists[key], key, gas)\n",
    "\n",
    "    # NA values for all entries of 'supra' columns of national jurisdictions\n",
    "\n",
    "    supra_cols = [\"ecp_ets_supraGHG_usd_k\", \"ecp_tax_supraGHG_usd_k\", \n",
    "                  \"ecp_ets_supra\"+gas+\"_usd_k\", \"ecp_tax_supra\"+gas+\"_usd_k\", \n",
    "                  \"ecp_all_supraGHG_usd_k\", \"ecp_all_supra\"+gas+\"_usd_k\"]\n",
    "\n",
    "    for df in [ecp_tv_agg[gas], ecp_fixed_agg[gas]]:\n",
    "        df.loc[~df.jurisdiction.isin(all_subnat_list), supra_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    col_sel = [\"jurisdiction\", \"year\", \n",
    "                \"ecp_ets_jurGHG_usd_k\", \"ecp_tax_jurGHG_usd_k\", \"ecp_all_jurGHG_usd_k\", \n",
    "                \"ecp_ets_jur\"+gas+\"_usd_k\", \"ecp_tax_jur\"+gas+\"_usd_k\", \"ecp_all_jur\"+gas+\"_usd_k\",\n",
    "                \"ecp_ets_supraGHG_usd_k\", \"ecp_tax_supraGHG_usd_k\", \"ecp_all_supraGHG_usd_k\", \n",
    "                \"ecp_ets_supra\"+gas+\"_usd_k\", \"ecp_tax_supra\"+gas+\"_usd_k\", \"ecp_all_supra\"+gas+\"_usd_k\"]\n",
    "\n",
    "    ecp_tv_agg[gas][col_sel].fillna(\"NA\").sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_vw/ecp_tv_\"+gas+\"_\"+d1+\".csv\", index=None)\n",
    "    ecp_fixed_agg[gas][col_sel].fillna(\"NA\").sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_fw/ecp_fixed_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Calculation of ECP from ETS and taxes (CO2 only, constant, jurisdiction-specific weights, jurisdiction level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information needed (need two dataframes): \n",
    "#- at sector level: year of first implementation of carbon pricing on any fuel (one with the list of jurisdiction and year of implementation of first scheme)\n",
    "#- at jurisdiction level: year of first implementation of carbon pricing in any sector (one with the list of jurisdiction-sector entries and year of implementation of first scheme)\n",
    "\n",
    "firstYear = wcpd_all[['jurisdiction', 'year', 'ipcc_code', 'iea_code', 'Product', 'tax', 'ets']]\n",
    "\n",
    "firstYear.loc[:, \"pricing\"] = firstYear.loc[:, \"tax\"] + firstYear.loc[:, \"ets\"]\n",
    "firstYear.loc[:, \"pricing\"] = np.where(firstYear.loc[:, \"pricing\"] > 0, 1.0,0.0)\n",
    "firstYear = firstYear.drop([\"tax\", \"ets\"], axis=1)\n",
    "firstYear = firstYear.loc[firstYear.pricing == 1,]\n",
    "firstYear.sort_values(by=[\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"], ascending=True, inplace=True)\n",
    "\n",
    "firstYear.drop_duplicates(subset=[\"jurisdiction\", \"ipcc_code\", \"Product\"], inplace=True)\n",
    "\n",
    "# jurisdiction-level, recording year prior to first year of pricing mechanism implementation\n",
    "firstYear_jur = firstYear.groupby([\"jurisdiction\", \"year\"]).sum()\n",
    "firstYear_jur.loc[:, \"pricing\"] = np.where(firstYear_jur.loc[:, \"pricing\"] > 0, 1.0, 0.0)\n",
    "firstYear_jur.reset_index(inplace=True)\n",
    "\n",
    "firstYear_jur = firstYear_jur.drop_duplicates(subset=[\"jurisdiction\"])\n",
    "firstYear_jur[\"year\"] = firstYear_jur[\"year\"]-1 # to take the year before first year of implementation\n",
    "firstYear_jur = firstYear_jur.drop(\"pricing\", axis=1)\n",
    "\n",
    "firstYear_jur = pd.Series(firstYear_jur.year.values,index=firstYear_jur.jurisdiction).to_dict()\n",
    "\n",
    "## adjustment needed for Finland and Poland - their respective schemes started in 1990 so 1989 should be the reference year for\n",
    "## emissions. However, because GHG/CO2 CAIT series start in 1990, shares series start in 1990\n",
    "firstYear_jur[\"Finland\"] = 1990\n",
    "firstYear_jur[\"Poland\"] = 1990\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function does not aggregate subnational prices to national level \n",
    "\n",
    "def ecp_constIntro():\n",
    "        \n",
    "    df_concat = pd.DataFrame()\n",
    "    gas = \"CO2\"\n",
    "\n",
    "    for jur in inventories[gas].jurisdiction.unique():\n",
    "\n",
    "        if jur in firstYear_jur.keys():\n",
    "            weight_year = firstYear_jur[jur]\n",
    "        else:\n",
    "            weight_year = 2015\n",
    "\n",
    "        temp_cp_jur = prices_usd[gas].loc[(prices_usd[gas][\"jurisdiction\"]==jur), :]\n",
    "        share_df_jur = inventories[gas][(inventories[gas][\"jurisdiction\"]==jur) & (inventories[gas][\"year\"]==weight_year)]\n",
    "        share_df_jur.drop([\"year\"], axis=1, inplace=True)\n",
    "        \n",
    "        # merging on `prices_temp` keys in this case because this is the dataframe with all years\n",
    "        temp_df = share_df_jur.merge(temp_cp_jur, on=[\"jurisdiction\", \"ipcc_code\", \"iea_code\", \"Product\"], how=\"right\")\n",
    "\n",
    "        ecp_variables_map = {\"ecp_ets_jurGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jurGHG\"), x))==True], \n",
    "                            \"ecp_ets_jur\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jur\"+gas), x))==True], \n",
    "                            \"ecp_ets_wldGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wldGHG\"), x))==True],\n",
    "                            \"ecp_ets_wld\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wld\"+gas), x))==True],\n",
    "                            \"ecp_tax_jurGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jurGHG\"), x))==True], \n",
    "                            \"ecp_tax_jur\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jur\"+gas), x))==True], \n",
    "                            \"ecp_tax_wldGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wldGHG\"), x))==True], \n",
    "                            \"ecp_tax_wld\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wld\"+gas), x))==True]}\n",
    "\n",
    "        for key in ecp_variables_map.keys():\n",
    "            temp_df[key] = 0\n",
    "            length = int(len(ecp_variables_map[key])/2)\n",
    "            \n",
    "            for i in range(0, length):\n",
    "                cols = ecp_variables_map[key]\n",
    "                cols.sort()\n",
    "                \n",
    "                temp_df[key] = temp_df[cols[i]]*temp_df[cols[i+length]] #+ #nan values need to be replaced with 0 otherwise the sum won't work\n",
    "            \n",
    "            temp_df[key] = temp_df[key].astype(float)\n",
    "        \n",
    "        temp_df = temp_df[[\"jurisdiction\", \"ipcc_code\", \"iea_code\", \"Product\", \"year\"]+list(ecp_variables_map.keys())] \n",
    "\n",
    "        temp_df = temp_df.fillna(0) # CHECK WHY \"NA\" VALUES ARE PRODUCED IN THE FIRST PLACE\n",
    "\n",
    "        temp_df[\"ecp_all_jurGHG_usd_k\"] = temp_df[\"ecp_tax_jurGHG_usd_k\"]+temp_df[\"ecp_ets_jurGHG_usd_k\"]\n",
    "        temp_df[\"ecp_all_jur\"+gas+\"_usd_k\"] = temp_df[\"ecp_tax_jur\"+gas+\"_usd_k\"]+temp_df[\"ecp_ets_jur\"+gas+\"_usd_k\"]\n",
    "        temp_df[\"ecp_all_wldGHG_usd_k\"] = temp_df[\"ecp_tax_wldGHG_usd_k\"]+temp_df[\"ecp_ets_wldGHG_usd_k\"]\n",
    "        temp_df[\"ecp_all_wld\"+gas+\"_usd_k\"] = temp_df[\"ecp_tax_wld\"+gas+\"_usd_k\"]+temp_df[\"ecp_ets_wld\"+gas+\"_usd_k\"]\n",
    "\n",
    "        for col in [\"ecp_tax_supraGHG_usd_k\", \"ecp_tax_supraCO2_usd_k\", \"ecp_ets_supraGHG_usd_k\", \"ecp_ets_supraCO2_usd_k\", \n",
    "                    \"ecp_all_supraGHG_usd_k\", \"ecp_all_supraCO2_usd_k\"]:\n",
    "            temp_df[col] = np.nan\n",
    "\n",
    "        y = ecp_wav.ecp_aggregation(temp_df, gas)\n",
    "\n",
    "        y = y.loc[y.jurisdiction!=\"World\"]\n",
    "\n",
    "        y = y.groupby([\"jurisdiction\", \"year\"]).sum()\n",
    "        y.reset_index(inplace=True)\n",
    "\n",
    "        if df_concat.empty == True:\n",
    "            df_concat = y\n",
    "        else:\n",
    "            df_concat = pd.concat([df_concat, y])\n",
    "\n",
    "    return df_concat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_intro = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_intro[gas] = ecp_constIntro()\n",
    "\n",
    "    col_sel = [\"jurisdiction\", \"year\", \"ecp_ets_jurGHG_usd_k\", \"ecp_tax_jurGHG_usd_k\",\n",
    "               \"ecp_all_jurGHG_usd_k\", \"ecp_ets_jur\"+gas+\"_usd_k\", \"ecp_tax_jur\"+gas+\"_usd_k\", \"ecp_all_jur\"+gas+\"_usd_k\"]\n",
    "\n",
    "    ecp_intro[gas].loc[ecp_intro[gas].year<=2020][col_sel].to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_intro/ecp_intro_\"+gas+\".csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
