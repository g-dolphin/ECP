{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions-weighted carbon price"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[\"ipcc_code\"].replace(to_replace=category_names_ipcc_can_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  can[col].replace(to_replace={\"x\":None}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:176: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  usa[\"Gas\"].replace(to_replace={\"CO2 (combustion)\":\"CO2\", \"CO2 (non-combustion)\":\"CO2\"}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:198: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  usa[\"jurisdiction\"].replace(to_replace={\"Georgia\":\"Georgia_US\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import gc\n",
    "import os\n",
    "\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%b-%d-%Y\")\n",
    "\n",
    "# changing file paths \n",
    "path_dependencies = '/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp'\n",
    "exec(open(path_dependencies+'/pkgs_and_directories.py').read())\n",
    "exec(open(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/WorldCarbonPricingDatabase/_code/_compilation/_dependencies/jurisdictions.py\").read())\n",
    "\n",
    "subnat_lists = {\"United States\":jurisdictions[\"subnationals\"][\"United States\"], \"Canada\":jurisdictions[\"subnationals\"][\"Canada\"], \"China\":jurisdictions[\"subnationals\"][\"China\"]}\n",
    "all_subnat_list = jurisdictions[\"subnationals\"][\"United States\"]+jurisdictions[\"subnationals\"][\"Canada\"]+jurisdictions[\"subnationals\"][\"China\"]\n",
    "\n",
    "# just test ch4 and n2o \n",
    "gases = [\"CO2\", \"CH4\", \"N2O\"] # \"CH4\", \"N2O\", \"FGASES\" \n",
    "\n",
    "\n",
    "lastInvYear = {\"national\":2022, \"subnat\":{\"Canada\":2021, \"United States\":2021, \"China\":2018}} \n",
    "lastDbYear = 2024\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Institutional design (World Carbon Pricing Database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coverageFactor dataframe contains duplicates! Correct before proceeding further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coverageFactor dataframe contains duplicates! Correct before proceeding further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coverageFactor dataframe contains duplicates! Correct before proceeding further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]] = 0\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.loc[:, \"overlap_\"+i[0]+\"_\"+i[1]+\"_ids\"] = inst_df_ids.loc[:, scheme_columns[i[0]]] + inst_df_ids.loc[:, scheme_columns[i[1]]]\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_overlap.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inst_df_ids.drop(ovp_columns[ovp_col], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "wcpd = {}\n",
    "\n",
    "ipcc_iea_map = pd.read_csv(\n",
    "    \"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_raw/_aux_files/ipcc2006_iea_category_codes.csv\",\n",
    "    usecols=[\"ipcc_code\", \"FLOW\"]\n",
    ").rename(columns={\"FLOW\": \"iea_code\"})\n",
    "\n",
    "for gas in gases: \n",
    "\n",
    "    # LOAD WCPD DATAFRAMES\n",
    "\n",
    "    wcpd_ctry = ecp_general.concatenate(path_wcpd+\"/\"+gas+\"/national\")\n",
    "    wcpd_subnat = ecp_general.concatenate(path_wcpd+\"/\"+gas+\"/subnational\")\n",
    "    wcpd_all = pd.concat([wcpd_ctry, wcpd_subnat]).sort_values(by=[\"jurisdiction\", \"year\"])\n",
    "\n",
    "    # Clean and deduplicate\n",
    "    wcpd_all[\"Product\"] = wcpd_all[\"Product\"].fillna('NA')\n",
    "    wcpd_all = wcpd_all.drop_duplicates(subset=[\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"])\n",
    "\n",
    "    # Add IEA sector codes\n",
    "    wcpd_all = wcpd_all.merge(ipcc_iea_map, on=\"ipcc_code\", how=\"left\")\n",
    "    wcpd_all[\"iea_code\"] = wcpd_all[\"iea_code\"].fillna('NA')\n",
    "\n",
    "    # Standardize jurisdiction names\n",
    "    def standardize(names):\n",
    "        return {name: name.replace(\".\", \"\").replace(\",\", \"\").replace(\" \", \"_\") for name in names}\n",
    "\n",
    "    ctry_names = wcpd_ctry[\"jurisdiction\"].unique()\n",
    "    subnat_names = wcpd_subnat[\"jurisdiction\"].unique()\n",
    "    countries_dic = standardize(ctry_names)\n",
    "    subnat_dic = standardize(subnat_names)\n",
    "\n",
    "    # Check for duplicates\n",
    "    if wcpd_all.duplicated([\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"]).any():\n",
    "        print(f\"The dataset for {gas} contains duplicates!\")\n",
    "\n",
    "    # ADD COVERAGE FACTORS \n",
    "\n",
    "    wcpd_all = ecp_cov_fac.coverageFactors(wcpd_all, gas)\n",
    "\n",
    "    # MECHANISM OVERLAP \n",
    "    overlap = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/WorldCarbonPricingDatabase/_raw/overlap/overlap_mechanisms_\"+gas+\".csv\")\n",
    "\n",
    "    wcpd_all = ecp_overlap.overlap(wcpd_all, overlap)\n",
    "\n",
    "    wcpd[gas] = wcpd_all\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions\n",
    "## I. National jurisdictions \n",
    "### I.A Total GHG emissions (EDGAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Warming Potential values\n",
    "ipcc_gwp = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_raw/ghg_inventory/gwp_list.csv\")\n",
    "ipcc_gwp_list = dict(zip(ipcc_gwp.edgar_label, ipcc_gwp.ar5_gwp_100y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGASES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N2O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jeodpp.jrc.ec.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "EDGAR_URL = \"https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/EDGAR/datasets/EDGAR_2024_GHG/\"\n",
    "\n",
    "dataURLs = {\"CH4\":EDGAR_URL+\"EDGAR_CH4_1970_2023.zip\",\n",
    "            \"CO2\":EDGAR_URL+\"IEA_EDGAR_CO2_1970_2023.zip\",\n",
    "            \"FGASES\":EDGAR_URL+\"EDGAR_F-gases_1990_2023.zip\",\n",
    "            \"N2O\":EDGAR_URL+\"EDGAR_N2O_1970_2023.zip\"}\n",
    "\n",
    "fileNames = {\"CH4\":'EDGAR_CH4_1970_2023.xlsx',\n",
    "            \"CO2\":\"IEA_EDGAR_CO2_1970_2023.xlsx\",\n",
    "            \"FGASES\":\"EDGAR_F-gases_1990_2023.xlsx\",\n",
    "            \"N2O\":\"EDGAR_N2O_1970_2023.xlsx\"}\n",
    "\n",
    "sheetNames = {\"CH4\":\"IPCC 2006\",\n",
    "              \"CO2\":\"IPCC 2006\",\n",
    "              \"FGASES\":\"IPCC 2006\",\n",
    "              \"N2O\":\"IPCC 2006\"}\n",
    "\n",
    "edgar_ghg = {}\n",
    "\n",
    "for gas in dataURLs.keys():\n",
    "    print(gas)\n",
    "    resp = requests.get(dataURLs[gas], verify=False).content\n",
    "\n",
    "    ## Open zip folder\n",
    "    myzip = ZipFile(BytesIO(resp))\n",
    "    #info = myzip.infolist()\n",
    "    #print(info)\n",
    "    \n",
    "    download = myzip.open(fileNames[gas])\n",
    "\n",
    "    df = pd.read_excel(download, header=0,\n",
    "                    sheet_name=sheetNames[gas], skiprows=[x for x in range(0,9)])\n",
    "    \n",
    "    edgar_ghg[gas] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concordance between EDGAR and World Bank country names\n",
    "edgar_wb_map = pd.read_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/aux_files/edgar_wb_ctry_name_map.csv\")\n",
    "edgar_wb_map = edgar_wb_map.loc[~edgar_wb_map.ctry_name_wb.isnull()]\n",
    "\n",
    "edgar_wb_map = dict(zip(list(edgar_wb_map['ctry_name_edgar'].values), list(edgar_wb_map['ctry_name_wb'].values)))\n",
    "\n",
    "def process_gas_dataframe(gas, df, gwp_dict, edgar_wb_map):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Filter to fossil emissions\n",
    "    df = df[df[\"fossil_bio\"] == \"fossil\"]\n",
    "\n",
    "    # Drop and rename columns\n",
    "    df = df.drop(columns=[\"IPCC_annex\", \"C_group_IM24_sh\", \"Country_code_A3\", \"fossil_bio\", \"ipcc_code_2006_for_standard_report_name\"])\n",
    "    df.rename(columns={\"Name\": \"jurisdiction\"}, inplace=True)\n",
    "\n",
    "    # Aggregate and reshape\n",
    "    df = df.groupby([\"jurisdiction\", \"ipcc_code_2006_for_standard_report\", \"Substance\"]).sum().reset_index()\n",
    "    df = df.melt(\n",
    "        id_vars=[\"jurisdiction\", \"ipcc_code_2006_for_standard_report\", \"Substance\"],\n",
    "        var_name=\"year\",\n",
    "        value_name=gas\n",
    "    )\n",
    "\n",
    "    # Clean and map\n",
    "    df[\"year\"] = df[\"year\"].str[2:].astype(int)\n",
    "    df[\"jurisdiction\"] = df[\"jurisdiction\"].replace(edgar_wb_map)\n",
    "\n",
    "    # Apply GWP\n",
    "    if gas in [\"CO2\", \"CH4\", \"N2O\"]:\n",
    "        df[gas] = df[gas] * gwp_dict[gas]\n",
    "        df.drop(columns=[\"Substance\"], inplace=True)\n",
    "        \n",
    "    # for FGASES ? \n",
    "    else:\n",
    "        df_gwp = pd.DataFrame({\"Substance\": gwp_dict.keys(), \"gwp\": gwp_dict.values()})\n",
    "        df = df.merge(df_gwp, on=\"Substance\", how=\"left\")\n",
    "        df[gas] = df[gas] * df[\"gwp\"]\n",
    "        # drop for combined FGASES \n",
    "        df.drop(columns=[\"gwp\", \"Substance\"], inplace=True)\n",
    "        df = df.groupby([\"jurisdiction\", \"year\", \"ipcc_code_2006_for_standard_report\"]).sum().reset_index()\n",
    "\n",
    "    # Final cleanup\n",
    "    df.rename(columns={\"ipcc_code_2006_for_standard_report\": \"ipcc_code\"}, inplace=True)\n",
    "\n",
    "    df[\"ipcc_code\"] = df[\"ipcc_code\"].apply(lambda x: x.replace('.', '').upper())\n",
    "    df[\"ipcc_code\"] = df[\"ipcc_code\"].apply(lambda x: x.replace('_NORES', '').upper())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Main processing ---\n",
    "df_gases = pd.DataFrame()\n",
    "\n",
    "for gas, df in edgar_ghg.items():\n",
    "    df_gas = process_gas_dataframe(gas, df, ipcc_gwp_list, edgar_wb_map)\n",
    "\n",
    "    if df_gases.empty:\n",
    "        df_gases = df_gas\n",
    "    else:\n",
    "        df_gases = df_gases.merge(df_gas, on=[\"jurisdiction\", \"year\", \"ipcc_code\"], how=\"outer\")\n",
    "\n",
    "# Compute total GHGs\n",
    "df_gases[\"all_GHG\"] = df_gases[list(edgar_ghg.keys())].sum(axis=1)\n",
    "\n",
    "# hadit \n",
    "df_gases_jurAgg = df_gases.groupby([\"jurisdiction\", \"year\"]).sum().reset_index()\n",
    "\n",
    "df_gases_jurAgg.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_national_total.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country names\n",
    "iea_wb_map = {'Australi':'Australia', \n",
    "            'Bosniaherz':'Bosnia and Herzegovina',\n",
    "            'Brunei':'Brunei Darussalam', \n",
    "            'Congo':'Congo, Rep.', \n",
    "            'Congorep':'Congo, Dem. Rep.',\n",
    "            'Costarica':'Costa Rica',\n",
    "            'Coteivoire':\"Cote d'Ivoire\", \n",
    "            'Czech':'Czech Republic',\n",
    "            'Dominicanr':'Dominican Republic',\n",
    "            'Egypt':'Egypt, Arab Rep.', \n",
    "            'Elsalvador':'El Salvador',\n",
    "            'Eqguinea':'Equatorial Guinea',\n",
    "            'Eswatini':'Lesotho', \n",
    "            'Hongkong':'Hong Kong, SAR', \n",
    "            'Iran':'Iran, Islamic, Rep.', \n",
    "            'Korea':'Korea, Rep.', \n",
    "            'Koreadpr':'Korea, Dem. Rep.', \n",
    "            'Kyrgyzstan':'Kyrgyz Republic', \n",
    "            'Lao':'Lao PDR', \n",
    "            'Luxembou':'Luxembourg',\n",
    "            'Nethland':'Netherlands',\n",
    "            'Northmaced':'North Macedonia',\n",
    "            'Nz':'New Zealand',\n",
    "            'Philippine':'Philippines',\n",
    "            'Russia':'Russian Federation',\n",
    "            'Saudiarabi':'Saudi Arabia', \n",
    "            'Slovakia':'Slovak Republic',\n",
    "            'Southafric':'South Africa',\n",
    "            'Srilanka':'Sri Lanka', \n",
    "            'Ssudan':'South Sudan', \n",
    "            'Switland':'Switzerland', \n",
    "            'Syria':'Syrian Arab Republic', \n",
    "            'Turkmenist':'Turkmenistan',\n",
    "            'Uae':'United Arab Emirates',\n",
    "            'Uk':'United Kingdom',\n",
    "            'Usa':'United States',\n",
    "            'Venezuela':'Venezuela, RB',\n",
    "            'Yemen':'Yemen, Rep.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DATAFRAME WITH TOTAL EMISSIONS WORLD\n",
    "\n",
    "df_gases_tot_world = df_gases_jurAgg.groupby(by=[\"year\"]).sum()\n",
    "df_gases_tot_world.reset_index(inplace=True)\n",
    "df_gases_tot_world.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_world_total.csv',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.B National GHG Inventory (kt and % of totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:137: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(to_replace=iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  edgar_ghg[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:137: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(to_replace=iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:163: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  edgar_ghg[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"CO2\"].replace({\"..\": np.nan, \"x\": np.nan, \"c\": np.nan}, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:64: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"jurisdiction\"].replace(iea_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:83: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ippu_fug_nat[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n",
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_nat.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ippu_fug_nat[\"jurisdiction\"].replace(edgar_wb_map, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "inventory_nat_ch4 = ecp_inv_nat.inventory_non_co2(wcpd_all, \"CH4\", ctry_names, iea_wb_map, edgar_wb_map)\n",
    "inventory_nat_n2o = ecp_inv_nat.inventory_non_co2(wcpd_all, \"N2O\", ctry_names, iea_wb_map, edgar_wb_map)\n",
    "inventory_nat_co2 = ecp_inv_nat.inventory_co2(wcpd_all, ctry_names, iea_wb_map, df_gases, edgar_wb_map)\n",
    "\n",
    "inventory_nat_ch4.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_ch4_ipcc.csv',index=None)\n",
    "inventory_nat_n2o.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_n2o_ipcc.csv',index=None)\n",
    "inventory_nat_co2.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_co2_ipcc.csv',index=None)\n",
    "\n",
    "inventories = {\"CO2\":inventory_nat_co2, \"CH4\":inventory_nat_ch4, \"N2O\":inventory_nat_n2o}\n",
    "inventories_wldSect = {}\n",
    "# test for the new IEA concordance \n",
    "#inventory_nonco2_iea = ecp_inv_nat.inventory_non_co2_iea(iea_wb_map)\n",
    "# output for comparison with EDGAR \n",
    "#inventory_nonco2_iea.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_non_co2_ipcc.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases: \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    print(gas)\n",
    "    \n",
    "    inventory_share = ecp_inv_share.emissions_share(inventories[gas], df_gases_jurAgg, df_gases_tot_world, gas)\n",
    "    \n",
    "    merge_keys = [\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]\n",
    "    columns = [\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\", gas]\n",
    "   \n",
    "    inventories[gas] = pd.merge(inventories[gas], inventory_share, on=merge_keys, how=\"left\")\n",
    "\n",
    "    inventories[gas].to_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_nat_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    # Shares of total world sector emissions\n",
    "    sectors_wld_total = inventories[gas][columns].groupby([\"ipcc_code\", \"year\"]).sum()\n",
    "    sectors_wld_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_wldSect[gas] = ecp_inv_share.emissions_share_wld_sectors(inventories[gas], sectors_wld_total, gas, \"national\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    for ctry in countries_dic.keys():\n",
    "        inventories[gas].loc[inventories[gas].jurisdiction==ctry, :].to_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/national/\"+gas+\"/inventory_\"+gas+\"_\"+countries_dic[ctry]+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Subnational jurisdictions\n",
    "### II.A Total GHG emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:43: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:176: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:198: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subnat_file = open(\"/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py\")\n",
    "read_file = subnat_file.read()\n",
    "exec(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gases_tot_subnat = ecp_inv_subnat.subnat_total()\n",
    "df_gases_tot_subnat.to_csv('/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/ghg_subnat_total.csv',index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.B Subnational inventory (kt and % totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:285: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  inventory_subnat = inventory_subnat.merge(combined_subnat, on=[\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\"], how=\"left\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_jur columns: Index(['jurisdiction', 'year', 'CO2', 'all_GHG'], dtype='object')\n",
      "temp_wld Index(['year', 'CO2_wld', 'all_GHG_wld'], dtype='object')\n",
      "emissions_share columns after merge with temp_jur: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'CO2',\n",
      "       'CO2_nat', 'all_GHG_nat'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_inventory_share_func.py:30: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  emissions_share = pd.merge(emissions, temp_jur, how='left', on=['jurisdiction','year'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emissions_share columns after merge with temp_wld: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'CO2',\n",
      "       'CO2_nat', 'all_GHG_nat', 'CO2_wld', 'all_GHG_wld'],\n",
      "      dtype='object')\n",
      "CO2_jurGHG\n",
      "Completed CO2_jurGHG\n",
      "CO2_jurCO2\n",
      "Completed CO2_jurCO2\n",
      "CO2_wldGHG\n",
      "Completed CO2_wldGHG\n",
      "CO2_wldCO2\n",
      "Completed CO2_wldCO2\n",
      "CO2_supraGHG\n",
      "Completed CO2_supraGHG\n",
      "CO2_supraCO2\n",
      "Completed CO2_supraCO2\n",
      "CH4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:285: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  inventory_subnat = inventory_subnat.merge(combined_subnat, on=[\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\"], how=\"left\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_jur columns: Index(['jurisdiction', 'year', 'CH4', 'all_GHG'], dtype='object')\n",
      "temp_wld Index(['year', 'CH4_wld', 'all_GHG_wld'], dtype='object')\n",
      "emissions_share columns after merge with temp_jur: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'CH4',\n",
      "       'CH4_nat', 'all_GHG_nat'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_inventory_share_func.py:30: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  emissions_share = pd.merge(emissions, temp_jur, how='left', on=['jurisdiction','year'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emissions_share columns after merge with temp_wld: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'CH4',\n",
      "       'CH4_nat', 'all_GHG_nat', 'CH4_wld', 'all_GHG_wld'],\n",
      "      dtype='object')\n",
      "CH4_jurGHG\n",
      "Completed CH4_jurGHG\n",
      "CH4_jurCH4\n",
      "Completed CH4_jurCH4\n",
      "CH4_wldGHG\n",
      "Completed CH4_wldGHG\n",
      "CH4_wldCH4\n",
      "Completed CH4_wldCH4\n",
      "CH4_supraGHG\n",
      "Completed CH4_supraGHG\n",
      "CH4_supraCH4\n",
      "Completed CH4_supraCH4\n",
      "N2O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/inventory_preproc_subnat.py:285: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  inventory_subnat = inventory_subnat.merge(combined_subnat, on=[\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\"], how=\"left\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_jur columns: Index(['jurisdiction', 'year', 'N2O', 'all_GHG'], dtype='object')\n",
      "temp_wld Index(['year', 'N2O_wld', 'all_GHG_wld'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_inventory_share_func.py:30: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  emissions_share = pd.merge(emissions, temp_jur, how='left', on=['jurisdiction','year'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emissions_share columns after merge with temp_jur: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'N2O',\n",
      "       'N2O_nat', 'all_GHG_nat'],\n",
      "      dtype='object')\n",
      "emissions_share columns after merge with temp_wld: Index(['supra_jur', 'jurisdiction', 'year', 'ipcc_code', 'iea_code', 'N2O',\n",
      "       'N2O_nat', 'all_GHG_nat', 'N2O_wld', 'all_GHG_wld'],\n",
      "      dtype='object')\n",
      "N2O_jurGHG\n",
      "Completed N2O_jurGHG\n",
      "N2O_jurN2O\n",
      "Completed N2O_jurN2O\n",
      "N2O_wldGHG\n",
      "Completed N2O_wldGHG\n",
      "N2O_wldN2O\n",
      "Completed N2O_wldN2O\n",
      "N2O_supraGHG\n",
      "Completed N2O_supraGHG\n",
      "N2O_supraN2O\n",
      "Completed N2O_supraN2O\n"
     ]
    }
   ],
   "source": [
    "inventories_subnat = {}\n",
    "inventories_subnat_wldSect = {}\n",
    "inventories_subnat_ctrySect = {}\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "    print(gas)\n",
    "    \n",
    "    inventory_subnat = ecp_inv_subnat.inventory_subnat(wcpd[gas], subnat_names, ipcc_iea_map, gas, subnat_lists)\n",
    "\n",
    "    inventory_subnat_share = ecp_inv_share.emissions_share(inventory_subnat, \n",
    "                                                           df_gases_tot_subnat, df_gases_tot_world, gas, df_gases_jurAgg, \"subnational\")\n",
    "\n",
    "    merge_keys = [\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\"]\n",
    "    columns = [\"supra_jur\", \"jurisdiction\", \"year\", \"ipcc_code\", gas]\n",
    "\n",
    "    inventories_subnat[gas] = pd.merge(inventory_subnat, inventory_subnat_share, on=merge_keys, how=\"left\")\n",
    "    inventories_subnat[gas].to_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/inventory_subnat_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    # Shares of total world sector emissions\n",
    "    sectors_wld_total = inventories[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", gas]].groupby([\"ipcc_code\", \"year\"]).sum()\n",
    "    sectors_wld_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_subnat_wldSect[gas] = ecp_inv_share.emissions_share_wld_sectors(inventories_subnat[gas], sectors_wld_total, gas, \"subnational\")\n",
    "\n",
    "    # Shares of total country-sector emissions\n",
    "    sectors_ctry_total = inventories[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", gas]].groupby([\"jurisdiction\", \"year\", \"ipcc_code\"]).sum()\n",
    "    sectors_ctry_total.reset_index(inplace=True)\n",
    "\n",
    "    inventories_subnat_ctrySect[gas] = ecp_inv_share.emissions_share_ctry_sectors(inventories_subnat[gas], sectors_ctry_total, gas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    inventories_subnat_ctrySect[gas].to_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/subnational/\"+gas+\"/sector_level/inventory_\"+gas+\".csv\", index=None)\n",
    "\n",
    "    for jur in subnat_dic.keys():\n",
    "        inventories_subnat[gas].loc[inventories_subnat[gas].jurisdiction==jur, :].to_csv(\"/Users/ejoiner/OneDrive - rff/ecp/ecp_dataset/source_data/ghg_inventory/processed/subnational/\"+gas+\"/inventory_\"+gas+\"_\"+subnat_dic[jur]+\".csv\", index=None)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage \n",
    "## I. Disaggregated coverage dataframes\n",
    "\n",
    "** Note: National and subnational inventories do not have the same level of disaggregation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ejoiner/OneDrive - rff/Documents/RFF Organization/Research Documents/WCPD/ECP/_code/compilation/_dependencies/dep_ecp/ecp_v3_coverage.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  temp[\"year\"].replace(to_replace={inv_end_year:yr}, inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# SHARE OF JURISDICTIONS TOTAL EMISSIONS\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gas \u001b[38;5;129;01min\u001b[39;00m gases:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     coverage_nat[gas] = \u001b[43mecp_coverage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43minventories\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgas\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlastInvYear\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnational\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlastDbYear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwcpd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgas\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnational\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     coverage_subnat[gas] = ecp_coverage.coverage(inventories_subnat[gas], lastInvYear[\u001b[33m\"\u001b[39m\u001b[33msubnat\u001b[39m\u001b[33m\"\u001b[39m], lastDbYear, wcpd[gas], gas,\n\u001b[32m     17\u001b[39m                                                  \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33msubnational\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m     coverage_all = pd.concat([coverage_nat[gas], coverage_subnat[gas]])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\OneDrive - rff\\Documents\\RFF Organization\\Research Documents\\WCPD\\ECP\\_code\\compilation\\_dependencies\\dep_ecp\\ecp_v3_coverage.py:91\u001b[39m, in \u001b[36mcoverage\u001b[39m\u001b[34m(inventory, inv_end_year, wcpd_end_year, wcpd_df, gas, int_sectors, jur_level, scope_year)\u001b[39m\n\u001b[32m     87\u001b[39m     wcpd_keys.remove(\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     89\u001b[39m     wcpd_temp.drop([\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m], axis=\u001b[32m1\u001b[39m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m temp = \u001b[43minventory_temp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwcpd_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwcpd_keys\u001b[49m\u001b[43m)\u001b[49m           \n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m#because two IPCC sectors might have the same IEA_CODE, the above merge command leads to a duplication of these entries. \u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m#We need keep only one of these\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scope_year != \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:10832\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10813\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10814\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10828\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10829\u001b[39m ) -> DataFrame:\n\u001b[32m  10830\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10833\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10836\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10839\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    170\u001b[39m     op = _MergeOperation(\n\u001b[32m    171\u001b[39m         left_df,\n\u001b[32m    172\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m         validate=validate,\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[39m, in \u001b[36m_MergeOperation.get_result\u001b[39m\u001b[34m(self, copy)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right = \u001b[38;5;28mself\u001b[39m._indicator_pre_merge(\u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right)\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m join_index, left_indexer, right_indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    888\u001b[39m result = \u001b[38;5;28mself\u001b[39m._reindex_and_concat(\n\u001b[32m    889\u001b[39m     join_index, left_indexer, right_indexer, copy=copy\n\u001b[32m    890\u001b[39m )\n\u001b[32m    891\u001b[39m result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[38;5;28mself\u001b[39m._merge_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[39m, in \u001b[36m_MergeOperation._get_join_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1147\u001b[39m     join_index, right_indexer, left_indexer = _left_join_on_index(\n\u001b[32m   1148\u001b[39m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m.right_join_keys, sort=\u001b[38;5;28mself\u001b[39m.sort\n\u001b[32m   1149\u001b[39m     )\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m     (left_indexer, right_indexer) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.right_index:\n\u001b[32m   1154\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.left) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[39m, in \u001b[36m_MergeOperation._get_join_indexers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how != \u001b[33m\"\u001b[39m\u001b[33masof\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhow\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1740\u001b[39m, in \u001b[36mget_join_indexers\u001b[39m\u001b[34m(left_keys, right_keys, sort, how)\u001b[39m\n\u001b[32m   1734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_keys) > \u001b[32m1\u001b[39m:\n\u001b[32m   1735\u001b[39m     \u001b[38;5;66;03m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[32m   1736\u001b[39m     mapped = (\n\u001b[32m   1737\u001b[39m         _factorize_keys(left_keys[n], right_keys[n], sort=sort)\n\u001b[32m   1738\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(left_keys))\n\u001b[32m   1739\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     zipped = \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1741\u001b[39m     llab, rlab, shape = (\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m zipped)\n\u001b[32m   1743\u001b[39m     \u001b[38;5;66;03m# get flat i8 keys from label lists\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1737\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1733\u001b[39m rkey: ArrayLike\n\u001b[32m   1734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_keys) > \u001b[32m1\u001b[39m:\n\u001b[32m   1735\u001b[39m     \u001b[38;5;66;03m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[32m   1736\u001b[39m     mapped = (\n\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m         \u001b[43m_factorize_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1738\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(left_keys))\n\u001b[32m   1739\u001b[39m     )\n\u001b[32m   1740\u001b[39m     zipped = \u001b[38;5;28mzip\u001b[39m(*mapped)\n\u001b[32m   1741\u001b[39m     llab, rlab, shape = (\u001b[38;5;28mlist\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m zipped)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ejoiner\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2563\u001b[39m, in \u001b[36m_factorize_keys\u001b[39m\u001b[34m(lk, rk, sort)\u001b[39m\n\u001b[32m   2561\u001b[39m     llab = rizer.factorize(lk)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   2562\u001b[39m     rlab = rizer.factorize(rk)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2563\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m llab.dtype == \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintp\u001b[49m\u001b[43m)\u001b[49m, llab.dtype\n\u001b[32m   2564\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m rlab.dtype == np.dtype(np.intp), rlab.dtype\n\u001b[32m   2566\u001b[39m count = rizer.get_count()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "coverage_nat = {}\n",
    "coverage_subnat = {}\n",
    "coverage = {}\n",
    "coverage_sect = {}\n",
    "coverage_nat_sect = {}\n",
    "coverage_subnat_sect = {}\n",
    "\n",
    "lastInvYear = {\"national\":2022, \"subnat\":2018}\n",
    "lastDbYear = 2024\n",
    "\n",
    "# SHARE OF JURISDICTIONS TOTAL EMISSIONS\n",
    "for gas in gases:\n",
    "\n",
    "    coverage_nat[gas] = ecp_coverage.coverage(inventories[gas], lastInvYear[\"national\"], lastDbYear, wcpd[gas], gas,\n",
    "                                              False, \"national\")\n",
    "    coverage_subnat[gas] = ecp_coverage.coverage(inventories_subnat[gas], lastInvYear[\"subnat\"], lastDbYear, wcpd[gas], gas,\n",
    "                                                 False, \"subnational\")\n",
    "\n",
    "    coverage_all = pd.concat([coverage_nat[gas], coverage_subnat[gas]])\n",
    "    coverage_all = coverage_all.loc[coverage_all[\"jurisdiction\"]!=\"World\", :]\n",
    "\n",
    "    # Coverage figures should be calculated only based on aggregation of the most disaggregated flows, not their higher-level aggregation. \n",
    "    #Otherwise this might result in double counting. Hence aggregate sectors should be dropped from coverage dataframe.\n",
    "    # It also currently excludes coverage of international aviation ('ABFLOW039') and marine ('ABFLOW040') bunkers \n",
    "    # as they are currently excluded from national total emissions.\n",
    "    # Drop combustion sectors that are aggregation of lower level sectors and concatenate all coverage dataframes into a single one*\n",
    "\n",
    "    flow_excl = ['1A', '1A1A', '1A1C', '1A2', '1A3'] #'1A1C' is exluded here as ABFLOW011 emissions are attributed twice (to both 1A1B and 1A1C)\n",
    "    coverage_all = coverage_all.loc[~coverage_all.ipcc_code.isin(flow_excl), :]\n",
    "\n",
    "    coverage[gas] = coverage_all\n",
    "\n",
    "\n",
    "    # SHARE OF SECTORS' GLOBAL TOTAL EMISSIONS\n",
    "\n",
    "    coverage_nat_sect[gas] = ecp_coverage.coverage(inventories_wldSect[gas], lastInvYear[\"national\"], lastDbYear, wcpd[gas], gas,\n",
    "                                True, \"national\")\n",
    "    coverage_subnat_sect[gas] = ecp_coverage.coverage(inventories_subnat_wldSect[gas], lastInvYear[\"subnat\"], lastDbYear, wcpd[gas], gas,\n",
    "                                    True, \"subnational\")\n",
    "\n",
    "    coverage_sect_all = pd.concat([coverage_nat_sect[gas], coverage_subnat_sect[gas]])\n",
    "    coverage_sect_all = coverage_sect_all.loc[coverage_sect_all[\"jurisdiction\"]!=\"World\", :]\n",
    "\n",
    "    coverage_sect[gas] = coverage_sect_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Aggregate coverage\n",
    "\n",
    "- \"The sum over all pricing mechanisms\" of [emissions_share x coverage_factor] minus the overlapping coverage\n",
    "\n",
    "We account for the fact that more than one tax scheme or ets scheme can apply to the same emissions. However, covered emissions should be counted only once when covered by one or more scheme. To calculate overlapping coverage at the sector-fuel level, we use the `overlap_` variable in `wcpd_all` dataframe created above.\n",
    "\n",
    "### II.1 jurisdictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cov = {}\n",
    "\n",
    "for gas in gases:\n",
    "    # Create dataframe to contain aggregate coverage\n",
    "    coverage_agg = coverage_all[[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]]\n",
    "\n",
    "    # TAXES\n",
    "\n",
    "    cov_tax_columns_jurGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"jurGHG\" in x]\n",
    "    cov_tax_columns_jurGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"jur\"+gas in x]\n",
    "    cov_tax_columns_wldGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"wldGHG\" in x]\n",
    "    cov_tax_columns_wldGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"wld\"+gas in x]\n",
    "    cov_tax_columns_supraGHG = [x for x in coverage_all.columns if \"cov_tax\" in x and \"supraGHG\" in x]\n",
    "    cov_tax_columns_supraGas = [x for x in coverage_all.columns if \"cov_tax\" in x and \"supra\"+gas in x]\n",
    "\n",
    "    tax_columns = {\"cov_tax_\"+gas+\"_jurGHG\":cov_tax_columns_jurGHG, \"cov_tax_\"+gas+\"_jur\"+gas:cov_tax_columns_jurGas, \n",
    "                \"cov_tax_\"+gas+\"_wldGHG\":cov_tax_columns_wldGHG, \"cov_tax_\"+gas+\"_wld\"+gas:cov_tax_columns_wldGas, \n",
    "                \"cov_tax_\"+gas+\"_supraGHG\":cov_tax_columns_supraGHG, \"cov_tax_\"+gas+\"_supra\"+gas:cov_tax_columns_supraGas}\n",
    "\n",
    "    # ETS\n",
    "\n",
    "    cov_ets_columns_jurGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"jurGHG\" in x]\n",
    "    cov_ets_columns_jurGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"jur\"+gas in x]\n",
    "    cov_ets_columns_wldGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"wldGHG\" in x]\n",
    "    cov_ets_columns_wldGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"wld\"+gas in x]\n",
    "    cov_ets_columns_supraGHG = [x for x in coverage_all.columns if \"cov_ets\" in x and \"supraGHG\" in x]\n",
    "    cov_ets_columns_supraGas = [x for x in coverage_all.columns if \"cov_ets\" in x and \"supra\"+gas in x]\n",
    "\n",
    "    ets_columns = {\"cov_ets_\"+gas+\"_jurGHG\":cov_ets_columns_jurGHG, \"cov_ets_\"+gas+\"_jur\"+gas:cov_ets_columns_jurGas, \n",
    "                \"cov_ets_\"+gas+\"_wldGHG\": cov_ets_columns_wldGHG, \"cov_ets_\"+gas+\"_wld\"+gas:cov_ets_columns_wldGas, \n",
    "                \"cov_ets_\"+gas+\"_supraGHG\":cov_ets_columns_supraGHG, \"cov_ets_\"+gas+\"_supra\"+gas:cov_ets_columns_supraGas}\n",
    "\n",
    "    # ALL INSTRUMENTS\n",
    "\n",
    "    cov_all_columns_jurGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"jurGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_jurGas = [x for x in coverage_all.columns if \"cov_\" in x and \"jur\"+gas in x and \"overlap\" not in x]\n",
    "    cov_all_columns_wldGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"wldGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_wldGas = [x for x in coverage_all.columns if \"cov_\" in x and \"wld\"+gas in x and \"overlap\" not in x]\n",
    "    cov_all_columns_supraGHG = [x for x in coverage_all.columns if \"cov_\" in x and \"supraGHG\" in x and \"overlap\" not in x]\n",
    "    cov_all_columns_supraGas = [x for x in coverage_all.columns if \"cov_\" in x and \"supra\"+gas in x and \"overlap\" not in x]\n",
    "\n",
    "    all_columns = {\"cov_all_\"+gas+\"_jurGHG\":cov_all_columns_jurGHG, \"cov_all_\"+gas+\"_jur\"+gas:cov_all_columns_jurGas, \n",
    "                \"cov_all_\"+gas+\"_wldGHG\":cov_all_columns_wldGHG, \"cov_all_\"+gas+\"_wld\"+gas:cov_all_columns_wldGas, \n",
    "                \"cov_all_\"+gas+\"_supraGHG\":cov_all_columns_supraGHG, \"cov_all_\"+gas+\"_supra\"+gas:cov_all_columns_supraGas}\n",
    "\n",
    "\n",
    "    all_overlap_dic = {\"cov_all_\"+gas+\"_jurGHG\":\"cov_overlap_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_jur\"+gas:\"cov_overlap_\"+gas+\"_jur\"+gas, \n",
    "                    \"cov_all_\"+gas+\"_wldGHG\":\"cov_overlap_\"+gas+\"_wldGHG\", \"cov_all_\"+gas+\"_wld\"+gas:\"cov_overlap_\"+gas+\"_wld\"+gas, \n",
    "                    \"cov_all_\"+gas+\"_supraGHG\":\"cov_overlap_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_supra\"+gas:\"cov_overlap_\"+gas+\"_supra\"+gas}\n",
    "\n",
    "    # Calculation of coverage\n",
    "\n",
    "    # An adjustment to the coverage function needs to be made. The function's output needs to include i) overlap across taxes, ii) overlap across ets, \n",
    "    # iii) overlap across all instruments\n",
    "\n",
    "    # A. Sum across all instruments (columns)\n",
    "\n",
    "    for dic in [tax_columns, ets_columns]: # [all_columns]\n",
    "        for key in dic.keys():\n",
    "            # sum across all instrument columns and substract overlaping coverage\n",
    "            coverage_agg[key] = coverage_all[dic[key]].sum(axis=1) # - coverage_all[all_overlap_dic[key]]\n",
    "\n",
    "    for dic in [all_columns]:\n",
    "        for key in dic.keys():\n",
    "            coverage_agg[key] = coverage_all[dic[key]].sum(axis=1) - coverage_all[all_overlap_dic[key]]\n",
    "\n",
    "    # B. Sum across all emission categories (rows)\n",
    "    coverage_agg = coverage_agg.groupby(['jurisdiction','year']).sum()\n",
    "    coverage_agg.reset_index(inplace=True)\n",
    "\n",
    "    agg_cov[gas] = coverage_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORLD TOTAL COVERAGE \n",
    "\n",
    "for gas in gases:\n",
    "    cov_world_agg = agg_cov[gas][[\"jurisdiction\",\"year\", \"cov_tax_\"+gas+\"_wld\"+gas, \"cov_ets_\"+gas+\"_wld\"+gas, \n",
    "                                        \"cov_tax_\"+gas+\"_wldGHG\", \"cov_ets_\"+gas+\"_wldGHG\"]]\n",
    "\n",
    "    cov_world_agg.reset_index(inplace=True)\n",
    "    cov_world_agg = cov_world_agg.groupby(['year']).sum()\n",
    "\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"] + cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas] + cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas]\n",
    "    \n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_wldGHG\"] = cov_world_agg[\"cov_all_\"+gas+\"_jurGHG\"]\n",
    "    cov_world_agg[\"cov_all_\"+gas+\"_wld\"+gas] = cov_world_agg[\"cov_all_\"+gas+\"_jur\"+gas]\n",
    "\n",
    "    # addind values in 'jur' columns for the \"World\" jurisdiction\n",
    "    cov_world_agg[\"cov_tax_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_ets_\"+gas+\"_jurGHG\"] = cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"]\n",
    "    cov_world_agg[\"cov_tax_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas]\n",
    "    cov_world_agg[\"cov_ets_\"+gas+\"_jur\"+gas] = cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas]\n",
    "\n",
    "#    cov_world_agg[\"cov_tax_\"+gas+\"_wldGHG\"] = \"NA\"\n",
    "#    cov_world_agg[\"cov_ets_\"+gas+\"_wldGHG\"] = \"NA\"\n",
    "#    cov_world_agg[\"cov_tax_\"+gas+\"_wld\"+gas] = \"NA\"\n",
    "#    cov_world_agg[\"cov_ets_\"+gas+\"_wld\"+gas] = \"NA\"\n",
    "\n",
    "    cov_world_agg[\"jurisdiction\"] = \"World\"\n",
    "\n",
    "    cov_world_agg.drop(\"index\", axis=1, inplace=True)\n",
    "    cov_world_agg.reset_index(inplace=True)\n",
    "\n",
    "    agg_cov[gas] = pd.concat([agg_cov[gas], cov_world_agg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# National-level coverage from subnational schemes\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "      for subnat_list in subnat_lists.keys():\n",
    "            temp = agg_cov[gas].loc[agg_cov[gas].jurisdiction.isin(subnat_lists[subnat_list]), :]\n",
    "            temp = temp.groupby([\"year\"]).sum()\n",
    "            temp.reset_index(inplace=True)\n",
    "            temp[\"jurisdiction\"] = subnat_list+\"_sub\" # indicating it is the country-level coverage from subnational mechanisms\n",
    "\n",
    "            temp[[\"cov_tax_\"+gas+\"_jurGHG\", \"cov_tax_\"+gas+\"_jur\"+gas, \"cov_ets_\"+gas+\"_jurGHG\", \"cov_ets_\"+gas+\"_jur\"+gas,\n",
    "                  \"cov_all_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_jur\"+gas]] = np.nan\n",
    "            \n",
    "            swap_list = {\"cov_tax_\"+gas+\"_jurGHG\":\"cov_tax_\"+gas+\"_supraGHG\", \"cov_tax_\"+gas+\"_jur\"+gas:\"cov_tax_\"+gas+\"_supra\"+gas, \"cov_ets_\"+gas+\"_jurGHG\":\"cov_ets_\"+gas+\"_supraGHG\", \n",
    "                        \"cov_ets_\"+gas+\"_jur\"+gas:\"cov_ets_\"+gas+\"_supra\"+gas, \"cov_all_\"+gas+\"_jurGHG\":\"cov_all_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_jur\"+gas:\"cov_all_\"+gas+\"_supra\"+gas,\n",
    "                        \"cov_tax_\"+gas+\"_supraGHG\":\"cov_tax_\"+gas+\"_jurGHG\", \"cov_tax_\"+gas+\"_supra\"+gas:\"cov_tax_\"+gas+\"_jur\"+gas, \"cov_ets_\"+gas+\"_supraGHG\":\"cov_ets_\"+gas+\"_jurGHG\", \n",
    "                        \"cov_ets_\"+gas+\"_supra\"+gas:\"cov_ets_\"+gas+\"_jur\"+gas, \"cov_all_\"+gas+\"_supraGHG\":\"cov_all_\"+gas+\"_jurGHG\", \"cov_all_\"+gas+\"_supra\"+gas:\"cov_all_\"+gas+\"_jur\"+gas}\n",
    "            \n",
    "            temp.rename(columns=swap_list, inplace=True)\n",
    "            \n",
    "            temp_nat = agg_cov[gas].loc[agg_cov[gas].jurisdiction == subnat_list, :]\n",
    "\n",
    "            temp_nat_subnat = pd.concat([temp_nat, temp])\n",
    "            temp_nat_subnat = temp_nat_subnat.groupby([\"year\"]).sum() # summing country-level coverage from country-level and subnational mechanisms\n",
    "            temp_nat_subnat.reset_index(inplace=True)\n",
    "\n",
    "            temp_nat_subnat[\"jurisdiction\"] = subnat_list\n",
    "\n",
    "            agg_cov[gas] = agg_cov[gas].loc[agg_cov[gas].jurisdiction != subnat_list, :]\n",
    "            \n",
    "            agg_cov[gas] = pd.concat([agg_cov[gas], temp_nat_subnat])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values for all entries of 'supra' columns of national jurisdictions\n",
    "\n",
    "all_subnat_list = subnat_usa + subnat_can + subnat_chn\n",
    "\n",
    "for gas in gases:\n",
    "\n",
    "    supra_cols = [\"cov_tax_\"+gas+\"_supraGHG\", \"cov_tax_\"+gas+\"_supra\"+gas, \"cov_ets_\"+gas+\"_supraGHG\", \n",
    "                \"cov_ets_\"+gas+\"_supra\"+gas, \"cov_all_\"+gas+\"_supraGHG\", \"cov_all_\"+gas+\"_supra\"+gas]\n",
    "\n",
    "    agg_cov[gas].loc[~agg_cov[gas].jurisdiction.isin(all_subnat_list), supra_cols] = np.nan\n",
    "\n",
    "    coverage_agg_OUT = agg_cov[gas].fillna(\"NA\")\n",
    "    coverage_agg_OUT.sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/coverage/tot_coverage_jurisdiction_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 World sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_WldSect = {}\n",
    "\n",
    "for gas in gases:\n",
    "    \n",
    "    coverage_sect[gas]\n",
    "\n",
    "    cov_tax_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_tax\" in x and \"wld_sect\" in x]\n",
    "    cov_ets_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_ets\" in x and \"wld_sect\" in x]\n",
    "    cov_all_columns_WldSectGas = [x for x in coverage_sect[gas].columns if \"cov_\" in x and \"wld_sect\" in x]\n",
    "\n",
    "    tax_columns = {\"cov_tax_\"+gas+\"_WldSect\"+gas:cov_tax_columns_WldSectGas}\n",
    "    ets_columns = {\"cov_ets_\"+gas+\"_WldSect\"+gas:cov_ets_columns_WldSectGas}\n",
    "    all_columns = {\"cov_all_\"+gas+\"_WldSect\"+gas:cov_all_columns_WldSectGas}\n",
    "\n",
    "    coverage_sect_agg_schemes = coverage_sect[gas][[\"jurisdiction\", \"year\", \"ipcc_code\", \"iea_code\", \"Product\"]]\n",
    "\n",
    "    for dic in [tax_columns, ets_columns, all_columns]:\n",
    "        for key in dic.keys():\n",
    "            coverage_sect_agg_schemes[key] = coverage_sect[gas][dic[key]].sum(axis=1)\n",
    "\n",
    "    coverage_WldSect[gas] = coverage_sect_agg_schemes.groupby(['ipcc_code','year']).sum()\n",
    "    coverage_WldSect[gas].reset_index(inplace=True)\n",
    "\n",
    "    coverage_WldSect[gas].to_csv(path_aux_data+\"/data/coverage/tot_coverage_world_sectors_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions-weighted Carbon Price (ECP)\n",
    "Combines: (i) (total) coverage of ETS and associated price, (ii) user-fuel coverage of taxes and associated tax rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_usd = {}\n",
    "\n",
    "for gas in gases:\n",
    "    # simply execute function to create cFlxRate series\n",
    "    ecp_cur_conv.cur_conv(wcpd[gas], gas, subnat_can, subnat_usa, subnat_chn, False, None)\n",
    "\n",
    "    wcpd_usd = ecp_cur_conv.cur_conv(wcpd[gas], gas, subnat_can, subnat_usa, subnat_chn, True, 2021)\n",
    "\n",
    "    #Bring together calculated emissions share at sector and sector-fuel level and carbon prices in constant USD\n",
    "\n",
    "    id_columns = [x for x in wcpd_usd.columns if bool(re.match(re.compile(\"ets.+id\"), x))==True or bool(re.match(re.compile(\"tax.+id\"), x))==True]\n",
    "    price_columns = [x for x in wcpd_usd.columns if bool(re.match(re.compile(\"ets.+price_usd_k\"), x))==True or bool(re.match(re.compile(\"tax.+rate.+usd_k\"), x))==True]\n",
    "\n",
    "    prices_usd[gas] = wcpd_usd[['jurisdiction', 'year', 'ipcc_code', 'iea_code', 'Product']+price_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. ECP from ETS and taxes (time-varying and fixed weights, jurisdiction level)\n",
    "\n",
    "National and subnational jurisdictions, sectoral level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_variables_map = {}\n",
    "\n",
    "ecp_tv = {}\n",
    "ecp_fixed = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_tv_nat = ecp_wav.ecp(coverage_nat[gas], prices_usd[gas], \"national\", gas, flow_excl, \"time_varying\", sectors=False)\n",
    "    ecp_tv_subnat = ecp_wav.ecp(coverage_subnat[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"time_varying\", sectors=False)\n",
    "    \n",
    "    ecp_tv[gas] = pd.concat([ecp_tv_nat, ecp_tv_subnat])\n",
    "\n",
    "    ecp_fixed_nat = ecp_wav.ecp(coverage_nat[gas], prices_usd[gas], \"national\", gas, flow_excl, \"fixed\", 2015, sectors=False)\n",
    "    ecp_fixed_subnat = ecp_wav.ecp(coverage_subnat[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"fixed\", 2015, sectors=False)\n",
    "    \n",
    "    ecp_fixed[gas] = pd.concat([ecp_fixed_nat, ecp_fixed_subnat])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_tv_sect = {}\n",
    "ecp_fixed_sect = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_tv_nat_sect = ecp_wav.ecp(coverage_nat_sect[gas], prices_usd[gas], \"national\", gas, flow_excl, \"time_varying\", sectors=True)\n",
    "    ecp_tv_subnat_sect = ecp_wav.ecp(coverage_subnat_sect[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"time_varying\", sectors=True)\n",
    "    \n",
    "    ecp_tv_sect[gas] = pd.concat([ecp_tv_nat_sect, ecp_tv_subnat_sect])\n",
    "    ecp_tv_nat_sect.groupby([\"ipcc_code\", \"year\"]).sum().to_csv(path_aux_data+\"/data/ecp/ecp_sectors_wld/world_sectoral_ecp_\"+gas+\".csv\")\n",
    "\n",
    "    ecp_fixed_nat_sect = ecp_wav.ecp(coverage_nat_sect[gas], prices_usd[gas], \"national\", gas, flow_excl, \"fixed\", 2015, sectors=True)\n",
    "    ecp_fixed_subnat_sect = ecp_wav.ecp(coverage_subnat_sect[gas], prices_usd[gas], \"subnational\", gas, flow_excl, \"fixed\", 2015, sectors=True)\n",
    "    \n",
    "    ecp_fixed_sect[gas] = pd.concat([ecp_fixed_nat, ecp_fixed_subnat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_tv_agg = {}\n",
    "ecp_fixed_agg = {}\n",
    "\n",
    "for gas in gases: \n",
    "    ecp_tv_agg[gas] = ecp_wav.ecp_aggregation(ecp_tv[gas], gas)\n",
    "    ecp_fixed_agg[gas] = ecp_wav.ecp_aggregation(ecp_fixed[gas], gas)\n",
    "\n",
    "    # National-level ecp from subnational schemes        \n",
    "\n",
    "    for key in subnat_lists.keys():\n",
    "        ecp_tv_agg[gas] = ecp_wav.national_from_subnat(ecp_tv_agg[gas], subnat_lists[key], key, gas)\n",
    "        ecp_fixed_agg[gas] = ecp_wav.national_from_subnat(ecp_fixed_agg[gas], subnat_lists[key], key, gas)\n",
    "\n",
    "    # NA values for all entries of 'supra' columns of national jurisdictions\n",
    "\n",
    "    supra_cols = [\"ecp_ets_supraGHG_usd_k\", \"ecp_tax_supraGHG_usd_k\", \n",
    "                  \"ecp_ets_supra\"+gas+\"_usd_k\", \"ecp_tax_supra\"+gas+\"_usd_k\", \n",
    "                  \"ecp_all_supraGHG_usd_k\", \"ecp_all_supra\"+gas+\"_usd_k\"]\n",
    "\n",
    "    for df in [ecp_tv_agg[gas], ecp_fixed_agg[gas]]:\n",
    "        df.loc[~df.jurisdiction.isin(all_subnat_list), supra_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gas in gases:\n",
    "    col_sel = [\"jurisdiction\", \"year\", \n",
    "                \"ecp_ets_jurGHG_usd_k\", \"ecp_tax_jurGHG_usd_k\", \"ecp_all_jurGHG_usd_k\", \n",
    "                \"ecp_ets_jur\"+gas+\"_usd_k\", \"ecp_tax_jur\"+gas+\"_usd_k\", \"ecp_all_jur\"+gas+\"_usd_k\",\n",
    "                \"ecp_ets_supraGHG_usd_k\", \"ecp_tax_supraGHG_usd_k\", \"ecp_all_supraGHG_usd_k\", \n",
    "                \"ecp_ets_supra\"+gas+\"_usd_k\", \"ecp_tax_supra\"+gas+\"_usd_k\", \"ecp_all_supra\"+gas+\"_usd_k\"]\n",
    "\n",
    "    ecp_tv_agg[gas][col_sel].fillna(\"NA\").sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_vw/ecp_tv_\"+gas+\"_\"+d1+\".csv\", index=None)\n",
    "    ecp_fixed_agg[gas][col_sel].fillna(\"NA\").sort_values(by=[\"jurisdiction\", \"year\"]).to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_fw/ecp_fixed_\"+gas+\"_\"+d1+\".csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Calculation of ECP from ETS and taxes (CO2 only, constant, jurisdiction-specific weights, jurisdiction level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information needed (need two dataframes): \n",
    "#- at sector level: year of first implementation of carbon pricing on any fuel (one with the list of jurisdiction and year of implementation of first scheme)\n",
    "#- at jurisdiction level: year of first implementation of carbon pricing in any sector (one with the list of jurisdiction-sector entries and year of implementation of first scheme)\n",
    "\n",
    "firstYear = wcpd_all[['jurisdiction', 'year', 'ipcc_code', 'iea_code', 'Product', 'tax', 'ets']]\n",
    "\n",
    "firstYear.loc[:, \"pricing\"] = firstYear.loc[:, \"tax\"] + firstYear.loc[:, \"ets\"]\n",
    "firstYear.loc[:, \"pricing\"] = np.where(firstYear.loc[:, \"pricing\"] > 0, 1.0,0.0)\n",
    "firstYear = firstYear.drop([\"tax\", \"ets\"], axis=1)\n",
    "firstYear = firstYear.loc[firstYear.pricing == 1,]\n",
    "firstYear.sort_values(by=[\"jurisdiction\", \"year\", \"ipcc_code\", \"Product\"], ascending=True, inplace=True)\n",
    "\n",
    "firstYear.drop_duplicates(subset=[\"jurisdiction\", \"ipcc_code\", \"Product\"], inplace=True)\n",
    "\n",
    "# jurisdiction-level, recording year prior to first year of pricing mechanism implementation\n",
    "firstYear_jur = firstYear.groupby([\"jurisdiction\", \"year\"]).sum()\n",
    "firstYear_jur.loc[:, \"pricing\"] = np.where(firstYear_jur.loc[:, \"pricing\"] > 0, 1.0, 0.0)\n",
    "firstYear_jur.reset_index(inplace=True)\n",
    "\n",
    "firstYear_jur = firstYear_jur.drop_duplicates(subset=[\"jurisdiction\"])\n",
    "firstYear_jur[\"year\"] = firstYear_jur[\"year\"]-1 # to take the year before first year of implementation\n",
    "firstYear_jur = firstYear_jur.drop(\"pricing\", axis=1)\n",
    "\n",
    "firstYear_jur = pd.Series(firstYear_jur.year.values,index=firstYear_jur.jurisdiction).to_dict()\n",
    "\n",
    "## adjustment needed for Finland and Poland - their respective schemes started in 1990 so 1989 should be the reference year for\n",
    "## emissions. However, because GHG/CO2 CAIT series start in 1990, shares series start in 1990\n",
    "firstYear_jur[\"Finland\"] = 1990\n",
    "firstYear_jur[\"Poland\"] = 1990\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function does not aggregate subnational prices to national level \n",
    "\n",
    "def ecp_constIntro():\n",
    "        \n",
    "    df_concat = pd.DataFrame()\n",
    "    gas = \"CO2\"\n",
    "\n",
    "    for jur in inventories[gas].jurisdiction.unique():\n",
    "\n",
    "        if jur in firstYear_jur.keys():\n",
    "            weight_year = firstYear_jur[jur]\n",
    "        else:\n",
    "            weight_year = 2015\n",
    "\n",
    "        temp_cp_jur = prices_usd[gas].loc[(prices_usd[gas][\"jurisdiction\"]==jur), :]\n",
    "        share_df_jur = inventories[gas][(inventories[gas][\"jurisdiction\"]==jur) & (inventories[gas][\"year\"]==weight_year)]\n",
    "        share_df_jur.drop([\"year\"], axis=1, inplace=True)\n",
    "        \n",
    "        # merging on `prices_temp` keys in this case because this is the dataframe with all years\n",
    "        temp_df = share_df_jur.merge(temp_cp_jur, on=[\"jurisdiction\", \"ipcc_code\", \"iea_code\", \"Product\"], how=\"right\")\n",
    "\n",
    "        ecp_variables_map = {\"ecp_ets_jurGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jurGHG\"), x))==True], \n",
    "                            \"ecp_ets_jur\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jur\"+gas), x))==True], \n",
    "                            \"ecp_ets_wldGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wldGHG\"), x))==True],\n",
    "                            \"ecp_ets_wld\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"ets_+price+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wld\"+gas), x))==True],\n",
    "                            \"ecp_tax_jurGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jurGHG\"), x))==True], \n",
    "                            \"ecp_tax_jur\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+jur\"+gas), x))==True], \n",
    "                            \"ecp_tax_wldGHG_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wldGHG\"), x))==True], \n",
    "                            \"ecp_tax_wld\"+gas+\"_usd_k\":[x for x in list(temp_df.columns) if bool(re.match(re.compile(\"tax.+rate+.\"), x))==True or bool(re.match(re.compile(gas+\"_+wld\"+gas), x))==True]}\n",
    "\n",
    "        for key in ecp_variables_map.keys():\n",
    "            temp_df[key] = 0\n",
    "            length = int(len(ecp_variables_map[key])/2)\n",
    "            \n",
    "            for i in range(0, length):\n",
    "                cols = ecp_variables_map[key]\n",
    "                cols.sort()\n",
    "                \n",
    "                temp_df[key] = temp_df[cols[i]]*temp_df[cols[i+length]] #+ #nan values need to be replaced with 0 otherwise the sum won't work\n",
    "            \n",
    "            temp_df[key] = temp_df[key].astype(float)\n",
    "        \n",
    "        temp_df = temp_df[[\"jurisdiction\", \"ipcc_code\", \"iea_code\", \"Product\", \"year\"]+list(ecp_variables_map.keys())] \n",
    "\n",
    "        temp_df = temp_df.fillna(0) # CHECK WHY \"NA\" VALUES ARE PRODUCED IN THE FIRST PLACE\n",
    "\n",
    "        temp_df[\"ecp_all_jurGHG_usd_k\"] = temp_df[\"ecp_tax_jurGHG_usd_k\"]+temp_df[\"ecp_ets_jurGHG_usd_k\"]\n",
    "        temp_df[\"ecp_all_jur\"+gas+\"_usd_k\"] = temp_df[\"ecp_tax_jur\"+gas+\"_usd_k\"]+temp_df[\"ecp_ets_jur\"+gas+\"_usd_k\"]\n",
    "        temp_df[\"ecp_all_wldGHG_usd_k\"] = temp_df[\"ecp_tax_wldGHG_usd_k\"]+temp_df[\"ecp_ets_wldGHG_usd_k\"]\n",
    "        temp_df[\"ecp_all_wld\"+gas+\"_usd_k\"] = temp_df[\"ecp_tax_wld\"+gas+\"_usd_k\"]+temp_df[\"ecp_ets_wld\"+gas+\"_usd_k\"]\n",
    "\n",
    "        for col in [\"ecp_tax_supraGHG_usd_k\", \"ecp_tax_supraCO2_usd_k\", \"ecp_ets_supraGHG_usd_k\", \"ecp_ets_supraCO2_usd_k\", \n",
    "                    \"ecp_all_supraGHG_usd_k\", \"ecp_all_supraCO2_usd_k\"]:\n",
    "            temp_df[col] = np.nan\n",
    "\n",
    "        y = ecp_wav.ecp_aggregation(temp_df, gas)\n",
    "\n",
    "        y = y.loc[y.jurisdiction!=\"World\"]\n",
    "\n",
    "        y = y.groupby([\"jurisdiction\", \"year\"]).sum()\n",
    "        y.reset_index(inplace=True)\n",
    "\n",
    "        if df_concat.empty == True:\n",
    "            df_concat = y\n",
    "        else:\n",
    "            df_concat = pd.concat([df_concat, y])\n",
    "\n",
    "    return df_concat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecp_intro = {}\n",
    "\n",
    "for gas in gases:\n",
    "    ecp_intro[gas] = ecp_constIntro()\n",
    "\n",
    "    col_sel = [\"jurisdiction\", \"year\", \"ecp_ets_jurGHG_usd_k\", \"ecp_tax_jurGHG_usd_k\",\n",
    "               \"ecp_all_jurGHG_usd_k\", \"ecp_ets_jur\"+gas+\"_usd_k\", \"ecp_tax_jur\"+gas+\"_usd_k\", \"ecp_all_jur\"+gas+\"_usd_k\"]\n",
    "\n",
    "    ecp_intro[gas].loc[ecp_intro[gas].year<=2020][col_sel].to_csv(path_aux_data+\"/data/ecp/ecp_economy/ecp_intro/ecp_intro_\"+gas+\".csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
